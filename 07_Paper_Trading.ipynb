{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29c2c0d4",
   "metadata": {},
   "source": [
    "#### Saturday, February 14, 2026\n",
    "\n",
    "This all runs in one pass, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s01-intro",
   "metadata": {},
   "source": [
    "# 07 - Paper Trading System: From Backtest to Live Simulation\n",
    "\n",
    "This capstone notebook ties together **everything from notebooks 01-06** into a unified\n",
    "paper trading system. It replays historical data bar-by-bar (simulation mode) or connects\n",
    "to the **Alpaca API** for real paper trading.\n",
    "\n",
    "---\n",
    "\n",
    "## What You'll Build\n",
    "\n",
    "1. **Market Data Engine** -- Unified interface for simulation replay and live data\n",
    "2. **Signal Integration Hub** -- All 10 signals from NB06 computed on streaming bars\n",
    "3. **Regime-Aware Scoring** -- Adaptive composite scoring for live decisions\n",
    "4. **Order Management System** -- Paper position tracking with Alpaca API integration\n",
    "5. **Pre-Market Scanner** -- Morning stock ranking by signal strength\n",
    "6. **Live Trading Loop** -- Event-driven bar -> signal -> trade pipeline\n",
    "7. **Interactive Dashboard** -- Plotly 4-panel real-time visualization\n",
    "8. **Trade Persistence** -- SQLite database for trade history\n",
    "9. **QuantStats Tearsheet** -- Professional performance reporting vs SPY benchmark\n",
    "10. **Statistical Validation** -- Bootstrap Sharpe CI, t-tests, distribution analysis\n",
    "11. **Risk Management Dashboard** -- Drawdown zones, concentration, rolling metrics\n",
    "\n",
    "---\n",
    "\n",
    "## System Architecture\n",
    "\n",
    "```\n",
    "                    +-------------------------------------+\n",
    "                    |         Pre-Market Scanner           |\n",
    "                    |  (overnight news, Chronos forecasts) |\n",
    "                    +-----------------+-------------------+\n",
    "                                      | ranked universe\n",
    "                    +-----------------v-------------------+\n",
    "                    |        Market Data Engine            |\n",
    "                    |  SimulationReplayer <--> Alpaca API  |\n",
    "                    +-----------------+-------------------+\n",
    "                                      | bar events\n",
    "                    +-----------------v-------------------+\n",
    "                    |        Signal Integration Hub       |\n",
    "                    |  Technical | Momentum | Sentiment   |\n",
    "                    |  Chronos   | Volume   | Mean-Rev    |\n",
    "                    +-----------------+-------------------+\n",
    "                                      | 10 normalized signals\n",
    "                    +-----------------v-------------------+\n",
    "                    |     Regime-Aware Composite Score     |\n",
    "                    |  ADX regime -> adaptive weighting    |\n",
    "                    +-----------------+-------------------+\n",
    "                                      | score + agreement\n",
    "                    +-----------------v-------------------+\n",
    "                    |     Order Management System          |\n",
    "                    |  entries, exits, stops, sizing        |\n",
    "                    |  Internal ledger <--> Alpaca Orders  |\n",
    "                    +-----------------+-------------------+\n",
    "                                      | trades\n",
    "              +----------+------------+-----------+\n",
    "              v                       v                    v\n",
    "     +---------------+    +---------------+    +---------------+\n",
    "     |  SQLite DB    |    |  QuantStats   |    |  Risk Dash    |\n",
    "     |  (peewee)     |    |  Tearsheet    |    |  (Plotly)     |\n",
    "     +---------------+    +---------------+    +---------------+\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Design Philosophy\n",
    "\n",
    "| Principle | Implementation |\n",
    "|-----------|---------------|\n",
    "| **Simulation-first** | Works without any API keys -- replays yfinance bar-by-bar |\n",
    "| **Alpaca-ready** | Set `ALPACA_KEY`/`ALPACA_SECRET` env vars to paper trade live |\n",
    "| **Self-contained** | All classes defined fresh (no cross-notebook imports) |\n",
    "| **Lazy GPU loading** | Chronos/sentiment models load only when explicitly requested |\n",
    "| **10 normalized signals** | Same -1 to +1 system from NB06, regime-adaptive weighting |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s02-md",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Configuration & Environment Setup\n",
    "\n",
    "Install `alpaca-py` for paper trading API access (optional -- simulation mode\n",
    "works without it). All other dependencies are already installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "s02-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.6.0+cu124 | CUDA: True\n",
      "  alpaca-py: yes\n",
      "  plotly:    yes\n",
      "  quantstats: yes\n"
     ]
    }
   ],
   "source": [
    "# Uncomment to install optional dependencies:\n",
    "# !pip install alpaca-py peewee\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import time\n",
    "import json as _json\n",
    "import sqlite3\n",
    "import warnings\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional, Dict, List, Tuple\n",
    "from collections import defaultdict\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from ta.trend import EMAIndicator, SMAIndicator, MACD, ADXIndicator\n",
    "from ta.momentum import RSIIndicator\n",
    "from ta.volatility import BollingerBands, AverageTrueRange\n",
    "\n",
    "# Optional imports with graceful fallback\n",
    "HAS_PLOTLY = False\n",
    "try:\n",
    "    import plotly.graph_objects as go\n",
    "    from plotly.subplots import make_subplots\n",
    "    HAS_PLOTLY = True\n",
    "except ImportError:\n",
    "    print(\"plotly not available -- install with: pip install plotly\")\n",
    "\n",
    "HAS_QUANTSTATS = False\n",
    "try:\n",
    "    import quantstats as qs\n",
    "    HAS_QUANTSTATS = True\n",
    "except ImportError:\n",
    "    print(\"quantstats not available -- install with: pip install quantstats\")\n",
    "\n",
    "HAS_ALPACA = False\n",
    "try:\n",
    "    from alpaca.trading.client import TradingClient\n",
    "    from alpaca.trading.requests import MarketOrderRequest\n",
    "    from alpaca.trading.enums import OrderSide, TimeInForce, OrderStatus\n",
    "    HAS_ALPACA = True\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "plt.style.use(\"dark_background\")\n",
    "sns.set_palette(\"bright\")\n",
    "\n",
    "print(f\"PyTorch: {torch.__version__} | CUDA: {torch.cuda.is_available()}\")\n",
    "print(f\"  alpaca-py: {'yes' if HAS_ALPACA else 'no (simulation only)'}\")\n",
    "print(f\"  plotly:    {'yes' if HAS_PLOTLY else 'no'}\")\n",
    "print(f\"  quantstats: {'yes' if HAS_QUANTSTATS else 'no'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "s02-config",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trading Config: LIVE PAPER mode\n",
      "  Universe: ['NVDA', 'AAPL', 'TSLA', 'AMD', 'MSFT', 'META', 'AMZN', 'GOOGL']\n",
      "  Capital: $100,000 | Max positions: 5\n",
      "--- Alpaca Connected ---\n",
      "  Buying power: $200,000.00\n",
      "  Equity:       $100,000.00\n",
      "  Day trades:   0/3\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class TradingConfig:\n",
    "    \"\"\"Central configuration for the paper trading system.\"\"\"\n",
    "    # Mode -- auto-detect: use live paper trading if Alpaca credentials are set\n",
    "    simulation_mode: bool = field(\n",
    "        default_factory=lambda: not bool(os.environ.get(\"ALPACA_KEY\"))\n",
    "    )\n",
    "\n",
    "    # Universe\n",
    "    universe: List[str] = field(default_factory=lambda: [\n",
    "        \"NVDA\", \"AAPL\", \"TSLA\", \"AMD\", \"MSFT\", \"META\", \"AMZN\", \"GOOGL\"\n",
    "    ])\n",
    "    benchmark: str = \"SPY\"\n",
    "\n",
    "    # Capital & Risk\n",
    "    initial_capital: float = 100_000.0\n",
    "    max_positions: int = 5\n",
    "    risk_per_trade_pct: float = 2.0        # percent of capital risked per trade\n",
    "    max_portfolio_risk: float = 0.06\n",
    "    max_per_stock_pct: float = 20.0        # max allocation per stock (%)\n",
    "\n",
    "    # Signal thresholds\n",
    "    entry_threshold: float = 0.3\n",
    "    exit_threshold: float = -0.1\n",
    "    min_agreement: float = 0.5             # min signal agreement ratio for entry\n",
    "\n",
    "    # Position management\n",
    "    atr_stop_mult: float = 2.0             # ATR multiplier for stop loss\n",
    "    atr_target_mult: float = 3.0           # ATR multiplier for take profit\n",
    "    max_hold_bars: int = 20                # max bars before forced exit\n",
    "    warmup_bars: int = 60                  # bars needed before signals are valid\n",
    "\n",
    "    # Execution\n",
    "    slippage_bps: float = 5.0\n",
    "    commission_per_share: float = 0.005\n",
    "\n",
    "    # Persistence\n",
    "    db_path: str = \"paper_trades.db\"\n",
    "\n",
    "    @property\n",
    "    def slippage_pct(self) -> float:\n",
    "        return self.slippage_bps / 10_000\n",
    "\n",
    "    # Alpaca (from environment variables)\n",
    "    alpaca_key: str = field(default_factory=lambda: os.environ.get(\"ALPACA_KEY\", \"\"))\n",
    "    alpaca_secret: str = field(default_factory=lambda: os.environ.get(\"ALPACA_SECRET\", \"\"))\n",
    "    alpaca_paper: bool = True\n",
    "\n",
    "CONFIG = TradingConfig()\n",
    "print(f\"Trading Config: {'SIMULATION' if CONFIG.simulation_mode else 'LIVE PAPER'} mode\")\n",
    "print(f\"  Universe: {CONFIG.universe}\")\n",
    "print(f\"  Capital: ${CONFIG.initial_capital:,.0f} | Max positions: {CONFIG.max_positions}\")\n",
    "\n",
    "# Try to connect to Alpaca if credentials are available\n",
    "alpaca_client = None\n",
    "if not CONFIG.simulation_mode and HAS_ALPACA and CONFIG.alpaca_key:\n",
    "    try:\n",
    "        alpaca_client = TradingClient(CONFIG.alpaca_key, CONFIG.alpaca_secret, paper=True)\n",
    "        account = alpaca_client.get_account()\n",
    "        print(f\"--- Alpaca Connected ---\")\n",
    "        print(f\"  Buying power: ${float(account.buying_power):,.2f}\")\n",
    "        print(f\"  Equity:       ${float(account.equity):,.2f}\")\n",
    "        print(f\"  Day trades:   {account.daytrade_count}/3\")\n",
    "    except Exception as e:\n",
    "        print(f\"Alpaca connection failed: {e}\")\n",
    "        print(\"Falling back to simulation mode.\")\n",
    "        CONFIG.simulation_mode = True\n",
    "else:\n",
    "    if not CONFIG.simulation_mode:\n",
    "        print(\"No Alpaca credentials. Set ALPACA_KEY and ALPACA_SECRET env vars.\")\n",
    "        CONFIG.simulation_mode = True\n",
    "    print(\"  (Set simulation_mode=False and provide Alpaca keys for live paper trading)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s03-md",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Market Data Engine\n",
    "\n",
    "The `SimulationReplayer` downloads historical data via yfinance and replays it\n",
    "bar-by-bar, simulating a live feed. The `MarketDataEngine` wraps this with a\n",
    "unified interface that works for both simulation and live modes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "s03-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MarketDataEngine ready (live mode)\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class BarEvent:\n",
    "    \"\"\"A single price bar event.\"\"\"\n",
    "    ticker: str\n",
    "    timestamp: pd.Timestamp\n",
    "    open: float\n",
    "    high: float\n",
    "    low: float\n",
    "    close: float\n",
    "    volume: float\n",
    "    bar_index: int\n",
    "\n",
    "\n",
    "class SimulationReplayer:\n",
    "    \"\"\"Replays historical yfinance data bar-by-bar, simulating a live feed.\"\"\"\n",
    "\n",
    "    def __init__(self, tickers, period=\"1y\", interval=\"1d\"):\n",
    "        self.tickers = tickers\n",
    "        self.data = {}\n",
    "        self.bar_index = 0\n",
    "\n",
    "        print(f\"Loading simulation data for {len(tickers)} tickers...\")\n",
    "        for ticker in tickers:\n",
    "            df = yf.download(ticker, period=period, interval=interval, progress=False)\n",
    "            if isinstance(df.columns, pd.MultiIndex):\n",
    "                df.columns = df.columns.get_level_values(0)\n",
    "            self.data[ticker] = df\n",
    "            print(f\"  {ticker}: {len(df)} bars | ${df['Close'].iloc[-1]:.2f}\")\n",
    "\n",
    "        common_dates = set.intersection(*[set(df.index) for df in self.data.values()])\n",
    "        self.common_dates = sorted(common_dates)\n",
    "        self.max_bars = len(self.common_dates)\n",
    "        print(f\"\\n{self.max_bars} common trading days loaded.\")\n",
    "\n",
    "    def get_history(self, ticker, up_to_bar):\n",
    "        \"\"\"Get all data up to and including the specified bar index.\"\"\"\n",
    "        if ticker not in self.data:\n",
    "            return None\n",
    "        date = self.common_dates[up_to_bar]\n",
    "        df = self.data[ticker]\n",
    "        return df[df.index <= date].copy()\n",
    "\n",
    "    def get_bar(self, ticker, bar_index):\n",
    "        \"\"\"Get a single bar event.\"\"\"\n",
    "        date = self.common_dates[bar_index]\n",
    "        df = self.data[ticker]\n",
    "        if date not in df.index:\n",
    "            return None\n",
    "        row = df.loc[date]\n",
    "        return BarEvent(\n",
    "            ticker=ticker, timestamp=date,\n",
    "            open=float(row[\"Open\"]), high=float(row[\"High\"]),\n",
    "            low=float(row[\"Low\"]), close=float(row[\"Close\"]),\n",
    "            volume=float(row[\"Volume\"]), bar_index=bar_index,\n",
    "        )\n",
    "\n",
    "    def iter_bars(self, warmup=60):\n",
    "        \"\"\"Iterate through bars, yielding dict of {ticker: BarEvent} per timestep.\"\"\"\n",
    "        for i in range(warmup, self.max_bars):\n",
    "            bars = {}\n",
    "            for ticker in self.tickers:\n",
    "                bar = self.get_bar(ticker, i)\n",
    "                if bar:\n",
    "                    bars[ticker] = bar\n",
    "            yield i, bars\n",
    "\n",
    "\n",
    "class MarketDataEngine:\n",
    "    \"\"\"Unified interface for simulation and live data.\"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.replayer = None\n",
    "        self._live_cache = {}\n",
    "\n",
    "        if config.simulation_mode:\n",
    "            self.replayer = SimulationReplayer(\n",
    "                config.universe + [config.benchmark],\n",
    "                period=\"1y\", interval=\"1d\"\n",
    "            )\n",
    "\n",
    "    def get_history(self, ticker, up_to_bar=None):\n",
    "        \"\"\"Get historical data for a ticker.\"\"\"\n",
    "        if self.config.simulation_mode and self.replayer:\n",
    "            if up_to_bar is not None:\n",
    "                return self.replayer.get_history(ticker, up_to_bar)\n",
    "            return self.replayer.data.get(ticker)\n",
    "        # Live mode: fetch from yfinance (cached per session)\n",
    "        if ticker not in self._live_cache:\n",
    "            df = yf.download(ticker, period=\"1y\", interval=\"1d\", progress=False)\n",
    "            if isinstance(df.columns, pd.MultiIndex):\n",
    "                df.columns = df.columns.get_level_values(0)\n",
    "            self._live_cache[ticker] = df if len(df) > 0 else None\n",
    "        return self._live_cache[ticker]\n",
    "\n",
    "    def iter_bars(self, warmup=60):\n",
    "        \"\"\"Iterate through bar events.\"\"\"\n",
    "        if self.config.simulation_mode and self.replayer:\n",
    "            yield from self.replayer.iter_bars(warmup=warmup)\n",
    "\n",
    "\n",
    "data_engine = MarketDataEngine(CONFIG)\n",
    "print(f\"\\nMarketDataEngine ready ({'simulation' if CONFIG.simulation_mode else 'live'} mode)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s04-md",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Signal Integration Hub\n",
    "\n",
    "All 10 signals from Notebook 06, adapted for streaming bar-by-bar computation.\n",
    "Each signal is normalized to **-1 (bearish)** to **+1 (bullish)**.\n",
    "\n",
    "| Category | Signals | Source |\n",
    "|----------|---------|--------|\n",
    "| **Trend** | EMA alignment, MACD histogram | NB03/06 |\n",
    "| **Momentum** | 5-day momentum, 20-day momentum, volume surge | NB06 |\n",
    "| **Reversion** | RSI, Bollinger Band position, 1-day mean reversion | NB03/06 |\n",
    "| **Sentiment** | FinBERT ensemble (or momentum proxy) | NB02 |\n",
    "| **Forecast** | Chronos prediction (or trend proxy) | NB04 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "s04-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal Hub Test (NVDA, latest bar):\n",
      "\n",
      "  sig_bb                    +0.229  +####\n",
      "  sig_chronos               -0.068  -#\n",
      "  sig_ema_trend             +1.000  +####################\n",
      "  sig_macd                  +0.049  +\n",
      "  sig_mean_reversion        +0.806  +################\n",
      "  sig_momentum_20d          -0.210  -####\n",
      "  sig_momentum_5d           -0.163  -###\n",
      "  sig_rsi                   +0.053  +#\n",
      "  sig_sentiment             -0.070  -#\n",
      "  sig_volume                +0.039  +\n",
      "\n",
      "  ADX: 11.7 | ATR: $6.41 | Close: $182.81\n"
     ]
    }
   ],
   "source": [
    "class TechnicalSignals:\n",
    "    \"\"\"Generate technical analysis signals (from Notebook 06).\n",
    "    All signals normalized to -1 (bearish) to +1 (bullish).\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def compute(df):\n",
    "        \"\"\"Add all technical signals to a DataFrame.\"\"\"\n",
    "        out = df.copy()\n",
    "\n",
    "        out[\"EMA_9\"] = EMAIndicator(df[\"Close\"], window=9).ema_indicator()\n",
    "        out[\"EMA_21\"] = EMAIndicator(df[\"Close\"], window=21).ema_indicator()\n",
    "        out[\"EMA_50\"] = EMAIndicator(df[\"Close\"], window=50).ema_indicator()\n",
    "        out[\"RSI\"] = RSIIndicator(df[\"Close\"], window=14).rsi()\n",
    "\n",
    "        macd = MACD(df[\"Close\"])\n",
    "        out[\"MACD_Hist\"] = macd.macd_diff()\n",
    "\n",
    "        bb = BollingerBands(df[\"Close\"])\n",
    "        out[\"BB_Upper\"] = bb.bollinger_hband()\n",
    "        out[\"BB_Lower\"] = bb.bollinger_lband()\n",
    "        out[\"BB_Middle\"] = bb.bollinger_mavg()\n",
    "\n",
    "        out[\"ATR\"] = AverageTrueRange(df[\"High\"], df[\"Low\"], df[\"Close\"]).average_true_range()\n",
    "        out[\"ADX\"] = ADXIndicator(df[\"High\"], df[\"Low\"], df[\"Close\"]).adx()\n",
    "\n",
    "        # --- Normalized Signals ---\n",
    "        ema_fast_above_slow = (out[\"EMA_9\"] > out[\"EMA_21\"]).astype(float)\n",
    "        ema_slow_above_long = (out[\"EMA_21\"] > out[\"EMA_50\"]).astype(float)\n",
    "        out[\"sig_ema_trend\"] = ema_fast_above_slow + ema_slow_above_long - 1.0\n",
    "\n",
    "        out[\"sig_rsi\"] = -1.0 * (out[\"RSI\"] - 50) / 50\n",
    "        out[\"sig_rsi\"] = out[\"sig_rsi\"].clip(-1, 1)\n",
    "\n",
    "        macd_max = out[\"MACD_Hist\"].rolling(50).apply(\n",
    "            lambda x: max(abs(x.max()), abs(x.min()), 1e-8))\n",
    "        out[\"sig_macd\"] = (out[\"MACD_Hist\"] / macd_max).clip(-1, 1)\n",
    "\n",
    "        bb_range = out[\"BB_Upper\"] - out[\"BB_Lower\"]\n",
    "        bb_position = (out[\"Close\"] - out[\"BB_Lower\"]) / bb_range.replace(0, np.nan)\n",
    "        out[\"sig_bb\"] = -1.0 * (bb_position * 2 - 1)\n",
    "        out[\"sig_bb\"] = out[\"sig_bb\"].clip(-1, 1)\n",
    "\n",
    "        out[\"trend_strength\"] = (out[\"ADX\"] / 50).clip(0, 1)\n",
    "        return out.dropna()\n",
    "\n",
    "\n",
    "class MomentumSignals:\n",
    "    \"\"\"Price momentum and mean-reversion signals.\"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def compute(df):\n",
    "        out = df.copy()\n",
    "        out[\"ret_1d\"] = out[\"Close\"].pct_change(1)\n",
    "        out[\"ret_5d\"] = out[\"Close\"].pct_change(5)\n",
    "        out[\"ret_20d\"] = out[\"Close\"].pct_change(20)\n",
    "\n",
    "        ret_5d_std = out[\"ret_5d\"].rolling(60).std()\n",
    "        out[\"sig_momentum_5d\"] = (out[\"ret_5d\"] / ret_5d_std.replace(0, np.nan)).clip(-2, 2) / 2\n",
    "\n",
    "        ret_20d_std = out[\"ret_20d\"].rolling(60).std()\n",
    "        out[\"sig_momentum_20d\"] = (out[\"ret_20d\"] / ret_20d_std.replace(0, np.nan)).clip(-2, 2) / 2\n",
    "\n",
    "        ret_1d_std = out[\"ret_1d\"].rolling(20).std()\n",
    "        z_score = out[\"ret_1d\"] / ret_1d_std.replace(0, np.nan)\n",
    "        out[\"sig_mean_reversion\"] = (-z_score).clip(-1, 1)\n",
    "\n",
    "        vol_avg = out[\"Volume\"].rolling(20).mean()\n",
    "        vol_ratio = out[\"Volume\"] / vol_avg.replace(0, np.nan)\n",
    "        out[\"sig_volume\"] = (np.sign(out[\"ret_1d\"]) * (vol_ratio - 1) / 2).clip(-1, 1)\n",
    "        return out.dropna()\n",
    "\n",
    "\n",
    "class LiveSentimentSignal:\n",
    "    \"\"\"Live sentiment signal using FinBERT (from NB02).\n",
    "    Loads model lazily. Falls back to momentum proxy if unavailable.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.pipeline = None\n",
    "        self.loaded = False\n",
    "\n",
    "    def load_model(self):\n",
    "        \"\"\"Explicitly load the FinBERT model onto GPU.\"\"\"\n",
    "        try:\n",
    "            from transformers import pipeline as hf_pipeline\n",
    "            self.pipeline = hf_pipeline(\n",
    "                \"sentiment-analysis\", model=\"ProsusAI/finbert\",\n",
    "                device=0 if torch.cuda.is_available() else -1,\n",
    "                truncation=True, max_length=512,\n",
    "            )\n",
    "            self.loaded = True\n",
    "            print(\"FinBERT loaded for live sentiment.\")\n",
    "        except Exception as e:\n",
    "            print(f\"FinBERT load failed: {e}. Using momentum proxy.\")\n",
    "            self.loaded = False\n",
    "\n",
    "    def compute(self, history_df, headlines=None):\n",
    "        \"\"\"Compute sentiment signal. Uses FinBERT if loaded, else momentum proxy.\"\"\"\n",
    "        if self.loaded and self.pipeline and headlines:\n",
    "            scores = []\n",
    "            for headline in headlines[:20]:\n",
    "                result = self.pipeline(headline)[0]\n",
    "                label = result[\"label\"].lower()\n",
    "                score = result[\"score\"]\n",
    "                if \"positive\" in label:\n",
    "                    scores.append(score)\n",
    "                elif \"negative\" in label:\n",
    "                    scores.append(-score)\n",
    "                else:\n",
    "                    scores.append(0.0)\n",
    "            return float(np.clip(np.mean(scores), -1, 1)) if scores else 0.0\n",
    "\n",
    "        ret_5d = history_df[\"Close\"].pct_change(5).iloc[-1]\n",
    "        return float(np.clip(ret_5d * 5, -1, 1))\n",
    "\n",
    "\n",
    "class LiveChronosSignal:\n",
    "    \"\"\"Live Chronos forecast signal (from NB04).\n",
    "    Loads model lazily. Falls back to trend proxy if unavailable.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.loaded = False\n",
    "\n",
    "    def load_model(self, model_name=\"amazon/chronos-bolt-small\"):\n",
    "        \"\"\"Explicitly load the Chronos model onto GPU.\"\"\"\n",
    "        try:\n",
    "            from chronos import ChronosBoltPipeline\n",
    "            self.model = ChronosBoltPipeline.from_pretrained(\n",
    "                model_name,\n",
    "                device_map=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "                torch_dtype=torch.float32,\n",
    "            )\n",
    "            self.loaded = True\n",
    "            print(f\"Chronos loaded: {model_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Chronos load failed: {e}. Using trend proxy.\")\n",
    "            self.loaded = False\n",
    "\n",
    "    def compute(self, history_df, horizon=5):\n",
    "        \"\"\"Compute forecast signal. +1 if price predicted up, -1 for down.\"\"\"\n",
    "        if self.loaded and self.model:\n",
    "            try:\n",
    "                prices = history_df[\"Close\"].values[-200:]\n",
    "                context = torch.tensor(prices, dtype=torch.float32)\n",
    "                forecast = self.model.predict(\n",
    "                    context=context, prediction_length=horizon, num_samples=100)\n",
    "                forecast_np = forecast.numpy()\n",
    "                median_end = np.median(forecast_np[:, -1])\n",
    "                current = prices[-1]\n",
    "                pct_change = (median_end - current) / current\n",
    "                return float(np.clip(pct_change * 20, -1, 1))\n",
    "            except Exception:\n",
    "                pass\n",
    "        ret_20d = history_df[\"Close\"].pct_change(20).iloc[-1]\n",
    "        return float(np.clip(ret_20d * 3, -1, 1))\n",
    "\n",
    "\n",
    "class SignalHub:\n",
    "    \"\"\"Aggregates all signal sources into a unified signal dictionary.\"\"\"\n",
    "\n",
    "    def __init__(self, config, use_sentiment=False, use_chronos=False):\n",
    "        self.config = config\n",
    "        self.sentiment_signal = LiveSentimentSignal()\n",
    "        self.chronos_signal = LiveChronosSignal()\n",
    "        if use_sentiment:\n",
    "            self.sentiment_signal.load_model()\n",
    "        if use_chronos:\n",
    "            self.chronos_signal.load_model()\n",
    "\n",
    "    def compute(self, history_df, headlines=None):\n",
    "        \"\"\"Compute all signals from price history. Returns dict for latest bar.\"\"\"\n",
    "        tech = TechnicalSignals.compute(history_df)\n",
    "        mom = MomentumSignals.compute(history_df)\n",
    "        if len(tech) == 0 or len(mom) == 0:\n",
    "            return None\n",
    "\n",
    "        signals = {}\n",
    "        last_tech = tech.iloc[-1]\n",
    "        for col in [\"sig_ema_trend\", \"sig_rsi\", \"sig_macd\", \"sig_bb\"]:\n",
    "            signals[col] = float(last_tech[col])\n",
    "        signals[\"trend_strength\"] = float(last_tech[\"trend_strength\"])\n",
    "        signals[\"ADX\"] = float(last_tech[\"ADX\"])\n",
    "        signals[\"ATR\"] = float(last_tech[\"ATR\"])\n",
    "        signals[\"EMA_50\"] = float(last_tech[\"EMA_50\"])\n",
    "        signals[\"close\"] = float(last_tech[\"Close\"])\n",
    "\n",
    "        last_mom = mom.iloc[-1]\n",
    "        for col in [\"sig_momentum_5d\", \"sig_momentum_20d\", \"sig_mean_reversion\", \"sig_volume\"]:\n",
    "            signals[col] = float(last_mom[col])\n",
    "\n",
    "        signals[\"sig_sentiment\"] = self.sentiment_signal.compute(history_df, headlines)\n",
    "        signals[\"sig_chronos\"] = self.chronos_signal.compute(history_df)\n",
    "        return signals\n",
    "\n",
    "\n",
    "# Test the signal hub on NVDA history\n",
    "signal_hub = SignalHub(CONFIG, use_sentiment=False, use_chronos=False)\n",
    "test_history = data_engine.get_history(\"NVDA\")\n",
    "test_signals = signal_hub.compute(test_history)\n",
    "\n",
    "print(\"Signal Hub Test (NVDA, latest bar):\\n\")\n",
    "if test_signals:\n",
    "    for key, val in sorted(test_signals.items()):\n",
    "        if key.startswith(\"sig_\"):\n",
    "            bar = \"#\" * int(abs(val) * 20)\n",
    "            direction = \"+\" if val > 0 else \"-\"\n",
    "            print(f\"  {key:<25} {val:>+6.3f}  {direction}{bar}\")\n",
    "    print(f\"\\n  ADX: {test_signals['ADX']:.1f} | ATR: ${test_signals['ATR']:.2f} | Close: ${test_signals['close']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s05-md",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Regime-Aware Composite Scoring\n",
    "\n",
    "Adapted from Notebook 06 for live, single-bar operation. The regime detector\n",
    "classifies the current market state, then applies adaptive weights to each\n",
    "signal category.\n",
    "\n",
    "| Regime | ADX | Trend Weight | Reversion Weight |\n",
    "|--------|-----|-------------|-----------------|\n",
    "| **Trend Up** | >25, price > EMA50 | 1.5x | 0.3x |\n",
    "| **Trend Down** | >25, price < EMA50 | 1.5x | 0.3x |\n",
    "| **Ranging** | <20 | 0.3x | 1.5x |\n",
    "| **Volatile** | 20-25 | 0.5x | 0.5x |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "s05-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVDA Regime Scoring Test:\n",
      "  Regime:      ranging\n",
      "  Composite:   +0.153\n",
      "  Agreement:   0.20\n",
      "  Action:      HOLD (score +0.153 between thresholds)\n"
     ]
    }
   ],
   "source": [
    "# Signal category definitions (same as NB06)\n",
    "SIGNAL_CATEGORIES = {\n",
    "    \"sig_ema_trend\":       (\"trend\",     1.0),\n",
    "    \"sig_macd\":            (\"trend\",     0.8),\n",
    "    \"sig_momentum_5d\":     (\"momentum\",  0.7),\n",
    "    \"sig_momentum_20d\":    (\"momentum\",  0.5),\n",
    "    \"sig_volume\":          (\"momentum\",  0.6),\n",
    "    \"sig_rsi\":             (\"reversion\", 0.8),\n",
    "    \"sig_bb\":              (\"reversion\", 0.7),\n",
    "    \"sig_mean_reversion\":  (\"reversion\", 0.5),\n",
    "    \"sig_sentiment\":       (\"sentiment\", 1.0),\n",
    "    \"sig_chronos\":         (\"forecast\",  1.0),\n",
    "}\n",
    "\n",
    "REGIME_WEIGHTS = {\n",
    "    \"trend_up\":   {\"trend\": 1.5, \"momentum\": 1.2, \"reversion\": 0.3, \"sentiment\": 1.0, \"forecast\": 1.0},\n",
    "    \"trend_down\": {\"trend\": 1.5, \"momentum\": 1.2, \"reversion\": 0.3, \"sentiment\": 1.0, \"forecast\": 1.0},\n",
    "    \"ranging\":    {\"trend\": 0.3, \"momentum\": 0.5, \"reversion\": 1.5, \"sentiment\": 1.2, \"forecast\": 0.8},\n",
    "    \"volatile\":   {\"trend\": 0.5, \"momentum\": 0.5, \"reversion\": 0.5, \"sentiment\": 0.8, \"forecast\": 0.5},\n",
    "}\n",
    "\n",
    "\n",
    "def classify_regime(signals: dict) -> str:\n",
    "    \"\"\"Classify market regime from signal dictionary.\"\"\"\n",
    "    adx = signals.get(\"ADX\", 20)\n",
    "    close = signals.get(\"close\", 0)\n",
    "    ema50 = signals.get(\"EMA_50\", close)\n",
    "    if adx > 25 and close > ema50:\n",
    "        return \"trend_up\"\n",
    "    elif adx > 25 and close <= ema50:\n",
    "        return \"trend_down\"\n",
    "    elif adx < 20:\n",
    "        return \"ranging\"\n",
    "    else:\n",
    "        return \"volatile\"\n",
    "\n",
    "\n",
    "def compute_composite_score_live(signals: dict, regime: str) -> Tuple[float, float]:\n",
    "    \"\"\"Compute regime-adaptive composite score from a signal dictionary.\n",
    "    Returns (composite_score, signal_agreement) both in [-1, +1] range.\"\"\"\n",
    "    regime_w = REGIME_WEIGHTS.get(regime, REGIME_WEIGHTS[\"volatile\"])\n",
    "    weighted_sum = 0.0\n",
    "    weight_sum = 0.0\n",
    "    signs = []\n",
    "\n",
    "    for signal_name, (category, base_weight) in SIGNAL_CATEGORIES.items():\n",
    "        if signal_name not in signals:\n",
    "            continue\n",
    "        total_weight = base_weight * regime_w.get(category, 1.0)\n",
    "        weighted_sum += signals[signal_name] * total_weight\n",
    "        weight_sum += total_weight\n",
    "        signs.append(np.sign(signals[signal_name]))\n",
    "\n",
    "    composite = float(np.clip(weighted_sum / max(weight_sum, 1e-8), -1, 1))\n",
    "    agreement = abs(sum(signs)) / max(len(signs), 1)\n",
    "    return composite, agreement\n",
    "\n",
    "\n",
    "# Test regime scoring\n",
    "if test_signals:\n",
    "    regime = classify_regime(test_signals)\n",
    "    score, agreement = compute_composite_score_live(test_signals, regime)\n",
    "    print(f\"NVDA Regime Scoring Test:\")\n",
    "    print(f\"  Regime:      {regime}\")\n",
    "    print(f\"  Composite:   {score:+.3f}\")\n",
    "    print(f\"  Agreement:   {agreement:.2f}\")\n",
    "    print(f\"  Action:      \", end=\"\")\n",
    "    if score > CONFIG.entry_threshold and agreement > CONFIG.min_agreement:\n",
    "        print(f\"BUY (score {score:+.3f} > {CONFIG.entry_threshold})\")\n",
    "    elif score < CONFIG.exit_threshold:\n",
    "        print(f\"SELL (score {score:+.3f} < {CONFIG.exit_threshold})\")\n",
    "    else:\n",
    "        print(f\"HOLD (score {score:+.3f} between thresholds)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s06-md",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Order Management System\n",
    "\n",
    "The `PaperTradingEngine` manages positions, risk, and trade execution. It\n",
    "maintains an internal ledger and optionally mirrors orders to Alpaca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "s06-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PaperTradingEngine ready.\n",
      "  Max positions: 5\n",
      "  Risk per trade: 2.0%\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class PaperPosition:\n",
    "    \"\"\"An open paper trading position.\"\"\"\n",
    "    ticker: str\n",
    "    direction: str\n",
    "    entry_date: pd.Timestamp\n",
    "    entry_price: float\n",
    "    shares: int\n",
    "    stop_loss: float\n",
    "    take_profit: float\n",
    "    entry_score: float\n",
    "    entry_regime: str\n",
    "    bars_held: int = 0\n",
    "    alpaca_order_id: str = \"\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class PaperTrade:\n",
    "    \"\"\"A completed trade record.\"\"\"\n",
    "    ticker: str\n",
    "    direction: str\n",
    "    entry_date: pd.Timestamp\n",
    "    exit_date: pd.Timestamp\n",
    "    entry_price: float\n",
    "    exit_price: float\n",
    "    shares: int\n",
    "    pnl: float\n",
    "    pnl_pct: float\n",
    "    exit_reason: str\n",
    "    entry_score: float\n",
    "    exit_score: float\n",
    "    regime: str\n",
    "    bars_held: int\n",
    "\n",
    "\n",
    "class PaperTradingEngine:\n",
    "    \"\"\"Paper trading engine with position tracking and risk management.\n",
    "    Maintains an internal ledger. When Alpaca client is provided,\n",
    "    mirrors orders to the paper trading API.\"\"\"\n",
    "\n",
    "    def __init__(self, config, alpaca_client=None):\n",
    "        self.config = config\n",
    "        self.alpaca = alpaca_client\n",
    "        self.capital = config.initial_capital\n",
    "        self.positions = {}\n",
    "        self.trades = []\n",
    "        self.equity_snapshots = []\n",
    "        self.signal_log = []\n",
    "\n",
    "    def snapshot_equity(self, bar_index, bars, timestamp):\n",
    "        \"\"\"Record current portfolio equity.\"\"\"\n",
    "        unrealized = 0\n",
    "        for ticker, pos in self.positions.items():\n",
    "            if ticker in bars:\n",
    "                current_price = bars[ticker].close\n",
    "                unrealized += (current_price - pos.entry_price) * pos.shares\n",
    "        self.equity_snapshots.append({\n",
    "            \"bar_index\": bar_index, \"date\": timestamp,\n",
    "            \"equity\": self.capital + unrealized,\n",
    "            \"cash\": self.capital, \"n_positions\": len(self.positions),\n",
    "            \"unrealized_pnl\": unrealized,\n",
    "        })\n",
    "\n",
    "    def check_exits(self, bars, signals_by_ticker):\n",
    "        \"\"\"Check all positions for exit conditions.\"\"\"\n",
    "        to_close = []\n",
    "        for ticker, pos in self.positions.items():\n",
    "            if ticker not in bars:\n",
    "                continue\n",
    "            bar = bars[ticker]\n",
    "            signals = signals_by_ticker.get(ticker, {})\n",
    "            regime = classify_regime(signals) if signals else \"volatile\"\n",
    "            score, _ = compute_composite_score_live(signals, regime) if signals else (0, 0)\n",
    "\n",
    "            exit_price = None\n",
    "            exit_reason = None\n",
    "\n",
    "            if bar.low <= pos.stop_loss:\n",
    "                exit_price = pos.stop_loss\n",
    "                exit_reason = \"stop_loss\"\n",
    "            elif bar.high >= pos.take_profit:\n",
    "                exit_price = pos.take_profit\n",
    "                exit_reason = \"take_profit\"\n",
    "            elif score < self.config.exit_threshold:\n",
    "                exit_price = bar.close * (1 - self.config.slippage_pct)\n",
    "                exit_reason = \"signal_exit\"\n",
    "            elif pos.bars_held >= self.config.max_hold_bars:\n",
    "                exit_price = bar.close * (1 - self.config.slippage_pct)\n",
    "                exit_reason = \"max_hold\"\n",
    "\n",
    "            if exit_price:\n",
    "                pnl = (exit_price - pos.entry_price) * pos.shares\n",
    "                pnl_pct = (exit_price / pos.entry_price - 1) * 100\n",
    "                self.capital += pos.entry_price * pos.shares + pnl\n",
    "\n",
    "                self.trades.append(PaperTrade(\n",
    "                    ticker=ticker, direction=pos.direction,\n",
    "                    entry_date=pos.entry_date, exit_date=bar.timestamp,\n",
    "                    entry_price=pos.entry_price, exit_price=exit_price,\n",
    "                    shares=pos.shares, pnl=pnl, pnl_pct=pnl_pct,\n",
    "                    exit_reason=exit_reason, entry_score=pos.entry_score,\n",
    "                    exit_score=score, regime=pos.entry_regime,\n",
    "                    bars_held=pos.bars_held,\n",
    "                ))\n",
    "                to_close.append(ticker)\n",
    "\n",
    "                if self.alpaca:\n",
    "                    try:\n",
    "                        order = MarketOrderRequest(\n",
    "                            symbol=ticker, qty=pos.shares,\n",
    "                            side=OrderSide.SELL, time_in_force=TimeInForce.DAY)\n",
    "                        self.alpaca.submit_order(order)\n",
    "                    except Exception as e:\n",
    "                        print(f\"  Alpaca sell failed for {ticker}: {e}\")\n",
    "\n",
    "        for ticker in to_close:\n",
    "            del self.positions[ticker]\n",
    "        return to_close\n",
    "\n",
    "    def check_entries(self, bars, signals_by_ticker):\n",
    "        \"\"\"Check for new entry opportunities.\"\"\"\n",
    "        if len(self.positions) >= self.config.max_positions:\n",
    "            return []\n",
    "\n",
    "        candidates = []\n",
    "        for ticker, signals in signals_by_ticker.items():\n",
    "            if ticker in self.positions or ticker == self.config.benchmark:\n",
    "                continue\n",
    "            if ticker not in bars:\n",
    "                continue\n",
    "            regime = classify_regime(signals)\n",
    "            score, agreement = compute_composite_score_live(signals, regime)\n",
    "            if score > self.config.entry_threshold and agreement > self.config.min_agreement:\n",
    "                candidates.append((ticker, score, agreement, regime, signals))\n",
    "\n",
    "        candidates.sort(key=lambda x: x[1], reverse=True)\n",
    "        slots = self.config.max_positions - len(self.positions)\n",
    "        entered = []\n",
    "\n",
    "        for ticker, score, agreement, regime, signals in candidates[:slots]:\n",
    "            bar = bars[ticker]\n",
    "            entry_price = bar.open * (1 + self.config.slippage_pct)\n",
    "            atr = signals.get(\"ATR\", entry_price * 0.02)\n",
    "\n",
    "            stop_loss = entry_price - self.config.atr_stop_mult * atr\n",
    "            take_profit = entry_price + self.config.atr_target_mult * atr\n",
    "\n",
    "            risk_amount = self.capital * (self.config.risk_per_trade_pct / 100)\n",
    "            risk_per_share = entry_price - stop_loss\n",
    "            if risk_per_share <= 0:\n",
    "                continue\n",
    "\n",
    "            shares = max(1, int(risk_amount / risk_per_share))\n",
    "            max_alloc = self.capital * (self.config.max_per_stock_pct / 100)\n",
    "            shares = min(shares, max(1, int(max_alloc / entry_price)))\n",
    "\n",
    "            cost = shares * entry_price\n",
    "            if cost > self.capital * 0.95:\n",
    "                continue\n",
    "\n",
    "            self.capital -= cost\n",
    "            self.positions[ticker] = PaperPosition(\n",
    "                ticker=ticker, direction=\"long\",\n",
    "                entry_date=bar.timestamp, entry_price=entry_price,\n",
    "                shares=shares, stop_loss=stop_loss, take_profit=take_profit,\n",
    "                entry_score=score, entry_regime=regime,\n",
    "            )\n",
    "            entered.append(ticker)\n",
    "\n",
    "            if self.alpaca:\n",
    "                try:\n",
    "                    order = MarketOrderRequest(\n",
    "                        symbol=ticker, qty=shares,\n",
    "                        side=OrderSide.BUY, time_in_force=TimeInForce.DAY)\n",
    "                    result = self.alpaca.submit_order(order)\n",
    "                    self.positions[ticker].alpaca_order_id = str(result.id)\n",
    "                except Exception as e:\n",
    "                    print(f\"  Alpaca buy failed for {ticker}: {e}\")\n",
    "\n",
    "        return entered\n",
    "\n",
    "    def close_all(self, bars):\n",
    "        \"\"\"Close all remaining positions at current prices.\"\"\"\n",
    "        for ticker, pos in list(self.positions.items()):\n",
    "            if ticker in bars:\n",
    "                exit_price = bars[ticker].close\n",
    "                pnl = (exit_price - pos.entry_price) * pos.shares\n",
    "                pnl_pct = (exit_price / pos.entry_price - 1) * 100\n",
    "                self.capital += pos.entry_price * pos.shares + pnl\n",
    "                self.trades.append(PaperTrade(\n",
    "                    ticker=ticker, direction=pos.direction,\n",
    "                    entry_date=pos.entry_date, exit_date=bars[ticker].timestamp,\n",
    "                    entry_price=pos.entry_price, exit_price=exit_price,\n",
    "                    shares=pos.shares, pnl=pnl, pnl_pct=pnl_pct,\n",
    "                    exit_reason=\"session_end\", entry_score=pos.entry_score,\n",
    "                    exit_score=0, regime=pos.entry_regime, bars_held=pos.bars_held,\n",
    "                ))\n",
    "        self.positions.clear()\n",
    "\n",
    "    def get_metrics(self):\n",
    "        \"\"\"Compute portfolio performance metrics.\"\"\"\n",
    "        if not self.trades:\n",
    "            return {\"total_trades\": 0}\n",
    "\n",
    "        pnls = [t.pnl for t in self.trades]\n",
    "        winners = [p for p in pnls if p > 0]\n",
    "        losers = [p for p in pnls if p <= 0]\n",
    "\n",
    "        equity_df = pd.DataFrame(self.equity_snapshots)\n",
    "        if len(equity_df) < 2:\n",
    "            return {\"total_trades\": len(self.trades), \"total_pnl\": sum(pnls)}\n",
    "\n",
    "        equity_df = equity_df.set_index(\"date\")\n",
    "        equity = equity_df[\"equity\"]\n",
    "        returns = equity.pct_change().dropna()\n",
    "        peak = equity.expanding().max()\n",
    "        drawdown = (equity - peak) / peak\n",
    "\n",
    "        sharpe = (returns.mean() / returns.std() * np.sqrt(252)) if returns.std() > 0 else 0\n",
    "        gross_profit = sum(winners) if winners else 0\n",
    "        gross_loss = abs(sum(losers)) if losers else 1\n",
    "\n",
    "        return {\n",
    "            \"total_trades\": len(self.trades),\n",
    "            \"winners\": len(winners),\n",
    "            \"losers\": len(losers),\n",
    "            \"win_rate\": len(winners) / len(self.trades) * 100,\n",
    "            \"total_pnl\": sum(pnls),\n",
    "            \"total_return_pct\": (equity.iloc[-1] / self.config.initial_capital - 1) * 100,\n",
    "            \"avg_trade_pnl\": np.mean(pnls),\n",
    "            \"avg_win\": np.mean(winners) if winners else 0,\n",
    "            \"avg_loss\": np.mean(losers) if losers else 0,\n",
    "            \"profit_factor\": gross_profit / gross_loss if gross_loss > 0 else float(\"inf\"),\n",
    "            \"sharpe_ratio\": sharpe,\n",
    "            \"max_drawdown_pct\": drawdown.min() * 100,\n",
    "            \"avg_bars_held\": np.mean([t.bars_held for t in self.trades]),\n",
    "            \"tickers_traded\": len(set(t.ticker for t in self.trades)),\n",
    "            \"exit_reasons\": pd.Series([t.exit_reason for t in self.trades]).value_counts().to_dict(),\n",
    "        }\n",
    "\n",
    "\n",
    "print(\"PaperTradingEngine ready.\")\n",
    "print(f\"  Max positions: {CONFIG.max_positions}\")\n",
    "print(f\"  Risk per trade: {CONFIG.risk_per_trade_pct}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s07-md",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Pre-Market Scanner\n",
    "\n",
    "Ranks the universe by signal strength before the session begins.\n",
    "In live mode, this would incorporate overnight news and pre-market data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "s07-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================================================================\n",
      "  PRE-MARKET SCANNER  |  8 stocks scanned\n",
      "===========================================================================\n",
      "\n",
      "  Ticker      Price   Score   Agree Regime       Action    \n",
      "  --------------------------------------------------------------\n",
      "      NVDA  $ 182.81 +0.153   0.20 ranging      --        \n",
      "      META  $ 639.77 +0.111   0.30 ranging      --        \n",
      "      AAPL  $ 255.78 +0.059   0.00 volatile     --        \n",
      "      TSLA  $ 417.44 -0.091   0.00 volatile     --        \n",
      "      AMD   $ 207.32 -0.210   0.60 volatile     --        \n",
      "      GOOGL $ 305.72 -0.288   0.10 trend_down   --        \n",
      "      MSFT  $ 401.32 -0.342   0.20 trend_down   --        \n",
      "      AMZN  $ 198.79 -0.557   0.40 trend_down   --        \n",
      "\n",
      "  Actionable: 0 stocks meet entry criteria\n"
     ]
    }
   ],
   "source": [
    "class PreMarketScanner:\n",
    "    \"\"\"Scan the stock universe and rank by composite signal strength.\"\"\"\n",
    "\n",
    "    def __init__(self, signal_hub, data_engine, config):\n",
    "        self.signal_hub = signal_hub\n",
    "        self.data_engine = data_engine\n",
    "        self.config = config\n",
    "\n",
    "    def scan(self, bar_index=None):\n",
    "        \"\"\"Scan all stocks and return ranked results.\"\"\"\n",
    "        results = []\n",
    "        for ticker in self.config.universe:\n",
    "            history = self.data_engine.get_history(ticker, bar_index)\n",
    "            if history is None or len(history) < self.config.warmup_bars:\n",
    "                continue\n",
    "            signals = self.signal_hub.compute(history)\n",
    "            if signals is None:\n",
    "                continue\n",
    "            regime = classify_regime(signals)\n",
    "            score, agreement = compute_composite_score_live(signals, regime)\n",
    "            results.append({\n",
    "                \"ticker\": ticker, \"close\": signals[\"close\"],\n",
    "                \"composite_score\": score, \"agreement\": agreement,\n",
    "                \"regime\": regime, \"ADX\": signals[\"ADX\"], \"ATR\": signals[\"ATR\"],\n",
    "                \"sig_ema_trend\": signals.get(\"sig_ema_trend\", 0),\n",
    "                \"sig_rsi\": signals.get(\"sig_rsi\", 0),\n",
    "                \"sig_momentum_5d\": signals.get(\"sig_momentum_5d\", 0),\n",
    "                \"sig_sentiment\": signals.get(\"sig_sentiment\", 0),\n",
    "                \"sig_chronos\": signals.get(\"sig_chronos\", 0),\n",
    "                \"actionable\": score > self.config.entry_threshold and agreement > self.config.min_agreement,\n",
    "            })\n",
    "        results.sort(key=lambda x: x[\"composite_score\"], reverse=True)\n",
    "        return results\n",
    "\n",
    "    def print_brief(self, results):\n",
    "        \"\"\"Print a formatted morning brief.\"\"\"\n",
    "        print(f\"\\n{'='*75}\")\n",
    "        print(f\"  PRE-MARKET SCANNER  |  {len(results)} stocks scanned\")\n",
    "        print(f\"{'='*75}\\n\")\n",
    "        print(f\"  {'Ticker':<8} {'Price':>8} {'Score':>7} {'Agree':>7} {'Regime':<12} {'Action':<10}\")\n",
    "        print(f\"  {'-'*62}\")\n",
    "        for r in results:\n",
    "            action = \"BUY\" if r[\"actionable\"] else \"--\"\n",
    "            icon = \">>>\" if r[\"actionable\"] else \"   \"\n",
    "            print(f\"  {icon} {r['ticker']:<5} ${r['close']:>7.2f} {r['composite_score']:>+6.3f} \"\n",
    "                  f\"{r['agreement']:>6.2f} {r['regime']:<12} {action:<10}\")\n",
    "        actionable = [r for r in results if r[\"actionable\"]]\n",
    "        print(f\"\\n  Actionable: {len(actionable)} stocks meet entry criteria\")\n",
    "        if actionable:\n",
    "            print(f\"  Top pick: {actionable[0]['ticker']} (score: {actionable[0]['composite_score']:+.3f})\")\n",
    "\n",
    "\n",
    "# Run pre-market scan\n",
    "scanner = PreMarketScanner(signal_hub, data_engine, CONFIG)\n",
    "last_bar = data_engine.replayer.max_bars - 1 if data_engine.replayer else None\n",
    "scan_results = scanner.scan(bar_index=last_bar)\n",
    "scanner.print_brief(scan_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s08-md",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Live Trading Loop\n",
    "\n",
    "The main event loop: for each bar, compute signals across the universe,\n",
    "check exits, check entries, log everything.\n",
    "\n",
    "```\n",
    "For each bar:\n",
    "  1. Compute signals for all tickers\n",
    "  2. Check existing positions for exits (stop/TP/signal/max_hold)\n",
    "  3. Check for new entry opportunities\n",
    "  4. Snapshot equity\n",
    "  5. Log signals to database\n",
    "  6. Increment bar counters\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "s08-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trading session function ready.\n",
      "Run with: engine = run_trading_session(CONFIG, data_engine, signal_hub)\n"
     ]
    }
   ],
   "source": [
    "def run_trading_session(config, data_engine, signal_hub, alpaca_client=None,\n",
    "                       verbose=True, progress_every=20):\n",
    "    \"\"\"Run a complete paper trading session.\n",
    "    In simulation mode, replays all historical bars.\n",
    "    Returns PaperTradingEngine with all trades, equity, and metrics.\"\"\"\n",
    "\n",
    "    engine = PaperTradingEngine(config, alpaca_client)\n",
    "\n",
    "    print(f\"{'='*60}\")\n",
    "    mode_label = \"(SIMULATION)\" if config.simulation_mode else \"(LIVE)\"\n",
    "    print(f\"  TRADING SESSION {mode_label}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"  Capital: ${config.initial_capital:,.0f} | Max positions: {config.max_positions}\")\n",
    "    print(f\"  Universe: {config.universe}\\n\")\n",
    "\n",
    "    t0 = time.time()\n",
    "    bar_count = 0\n",
    "    last_bars = None\n",
    "\n",
    "    for bar_index, bars in data_engine.iter_bars(warmup=config.warmup_bars):\n",
    "        bar_count += 1\n",
    "        last_bars = bars\n",
    "\n",
    "        # 1. Compute signals for all tickers\n",
    "        signals_by_ticker = {}\n",
    "        for ticker in config.universe:\n",
    "            history = data_engine.get_history(ticker, bar_index)\n",
    "            if history is not None and len(history) >= config.warmup_bars:\n",
    "                signals = signal_hub.compute(history)\n",
    "                if signals:\n",
    "                    regime = classify_regime(signals)\n",
    "                    score, agreement = compute_composite_score_live(signals, regime)\n",
    "                    signals[\"composite_score\"] = score\n",
    "                    signals[\"signal_agreement\"] = agreement\n",
    "                    signals[\"regime\"] = regime\n",
    "                    signals_by_ticker[ticker] = signals\n",
    "\n",
    "        # 2. Increment bars_held\n",
    "        for pos in engine.positions.values():\n",
    "            pos.bars_held += 1\n",
    "\n",
    "        # 3. Check exits\n",
    "        engine.check_exits(bars, signals_by_ticker)\n",
    "\n",
    "        # 4. Check entries\n",
    "        engine.check_entries(bars, signals_by_ticker)\n",
    "\n",
    "        # 5. Snapshot equity\n",
    "        timestamp = next(iter(bars.values())).timestamp if bars else None\n",
    "        if timestamp:\n",
    "            engine.snapshot_equity(bar_index, bars, timestamp)\n",
    "\n",
    "        # 6. Log signals\n",
    "        for ticker, signals in signals_by_ticker.items():\n",
    "            engine.signal_log.append({\n",
    "                \"bar_index\": bar_index, \"date\": str(timestamp),\n",
    "                \"ticker\": ticker,\n",
    "                \"composite_score\": signals.get(\"composite_score\", 0),\n",
    "                \"regime\": signals.get(\"regime\", \"\"),\n",
    "                \"agreement\": signals.get(\"signal_agreement\", 0),\n",
    "            })\n",
    "\n",
    "        # Progress reporting\n",
    "        if verbose and bar_count % progress_every == 0:\n",
    "            eq = engine.equity_snapshots[-1][\"equity\"] if engine.equity_snapshots else config.initial_capital\n",
    "            n_pos = len(engine.positions)\n",
    "            print(f\"  Bar {bar_count:>4} | {str(timestamp)[:10]} | \"\n",
    "                  f\"Equity: ${eq:>10,.0f} | Positions: {n_pos} | \"\n",
    "                  f\"Trades: {len(engine.trades)}\")\n",
    "\n",
    "    # Close remaining positions\n",
    "    if last_bars:\n",
    "        engine.close_all(last_bars)\n",
    "\n",
    "    elapsed = time.time() - t0\n",
    "    m = engine.get_metrics()\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"  SESSION COMPLETE ({elapsed:.1f}s, {bar_count} bars)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    if m.get(\"total_trades\", 0) > 0:\n",
    "        print(f\"  Total Trades:   {m['total_trades']}\")\n",
    "        print(f\"  Win / Lose:     {m.get('winners', 0)} / {m.get('losers', 0)}\")\n",
    "        print(f\"  Win Rate:       {m.get('win_rate', 0):.1f}%\")\n",
    "        print(f\"  Total P&L:      ${m.get('total_pnl', 0):>+10,.2f}\")\n",
    "        print(f\"  Total Return:   {m.get('total_return_pct', 0):>+10.2f}%\")\n",
    "        print(f\"  Sharpe Ratio:   {m.get('sharpe_ratio', 0):>10.2f}\")\n",
    "        print(f\"  Max Drawdown:   {m.get('max_drawdown_pct', 0):>10.2f}%\")\n",
    "        print(f\"  Profit Factor:  {m.get('profit_factor', 0):>10.2f}\")\n",
    "        print(f\"  Avg Hold (bars):{m.get('avg_bars_held', 0):>10.1f}\")\n",
    "        print(f\"  Exit Reasons:   {m.get('exit_reasons', {})}\")\n",
    "    else:\n",
    "        print(\"  No trades executed.\")\n",
    "\n",
    "    return engine\n",
    "\n",
    "\n",
    "print(\"Trading session function ready.\")\n",
    "print(\"Run with: engine = run_trading_session(CONFIG, data_engine, signal_hub)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s09-md",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Interactive Dashboard (Plotly)\n",
    "\n",
    "A 4-panel interactive dashboard showing:\n",
    "1. **Equity curve** with drawdown overlay\n",
    "2. **P&L by ticker** (bar chart)\n",
    "3. **Signal heatmap** over time\n",
    "4. **Trade log table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "s09-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard builder ready.\n",
      "  Using: Plotly (interactive)\n"
     ]
    }
   ],
   "source": [
    "def build_dashboard(engine, title=\"Paper Trading Dashboard\"):\n",
    "    \"\"\"Build an interactive Plotly dashboard from trading results.\n",
    "    Falls back to matplotlib if plotly is not available.\"\"\"\n",
    "    if not engine.trades:\n",
    "        print(\"No trades to display.\")\n",
    "        return\n",
    "\n",
    "    equity_df = pd.DataFrame(engine.equity_snapshots)\n",
    "    trade_df = pd.DataFrame([{\n",
    "        \"ticker\": t.ticker, \"entry\": str(t.entry_date)[:10],\n",
    "        \"exit\": str(t.exit_date)[:10], \"pnl\": t.pnl,\n",
    "        \"pnl_pct\": t.pnl_pct, \"exit_reason\": t.exit_reason,\n",
    "        \"bars_held\": t.bars_held, \"regime\": t.regime,\n",
    "    } for t in engine.trades])\n",
    "\n",
    "    if not HAS_PLOTLY:\n",
    "        print(\"Plotly not available -- using matplotlib fallback.\")\n",
    "        _dashboard_matplotlib(engine, equity_df, trade_df, title)\n",
    "        return\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=2,\n",
    "        subplot_titles=(\"Equity Curve\", \"P&L by Ticker\",\n",
    "                        \"Signal Scores Over Time\", \"Trade Log\"),\n",
    "        specs=[[{\"type\": \"scatter\"}, {\"type\": \"bar\"}],\n",
    "               [{\"type\": \"heatmap\"}, {\"type\": \"table\"}]],\n",
    "        vertical_spacing=0.12, horizontal_spacing=0.08,\n",
    "    )\n",
    "\n",
    "    # 1. Equity curve\n",
    "    if len(equity_df) > 0:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=equity_df[\"date\"], y=equity_df[\"equity\"],\n",
    "            mode=\"lines\", name=\"Equity\",\n",
    "            line=dict(color=\"cyan\", width=2),\n",
    "        ), row=1, col=1)\n",
    "        fig.add_hline(y=engine.config.initial_capital, line_dash=\"dash\",\n",
    "                      line_color=\"yellow\", opacity=0.5, row=1, col=1)\n",
    "\n",
    "    # 2. P&L by ticker\n",
    "    by_ticker = trade_df.groupby(\"ticker\")[\"pnl\"].sum().sort_values()\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=by_ticker.values, y=by_ticker.index, orientation=\"h\",\n",
    "        marker_color=[\"lime\" if v > 0 else \"red\" for v in by_ticker.values],\n",
    "        name=\"P&L\",\n",
    "    ), row=1, col=2)\n",
    "\n",
    "    # 3. Signal heatmap\n",
    "    signal_df = pd.DataFrame(engine.signal_log)\n",
    "    if len(signal_df) > 0:\n",
    "        pivot = signal_df.pivot_table(\n",
    "            index=\"ticker\", columns=\"date\", values=\"composite_score\", aggfunc=\"last\")\n",
    "        if pivot.shape[1] > 40:\n",
    "            pivot = pivot.iloc[:, ::pivot.shape[1] // 40]\n",
    "        fig.add_trace(go.Heatmap(\n",
    "            z=pivot.values,\n",
    "            x=[str(d)[:10] for d in pivot.columns],\n",
    "            y=pivot.index.tolist(),\n",
    "            colorscale=\"RdYlGn\", zmid=0, zmin=-1, zmax=1,\n",
    "            name=\"Composite Score\",\n",
    "        ), row=2, col=1)\n",
    "\n",
    "    # 4. Trade log table\n",
    "    if len(trade_df) > 0:\n",
    "        display_df = trade_df.tail(20)\n",
    "        fig.add_trace(go.Table(\n",
    "            header=dict(\n",
    "                values=[\"Ticker\", \"Entry\", \"Exit\", \"P&L\", \"P&L%\", \"Reason\"],\n",
    "                fill_color=\"rgb(30,30,30)\", font=dict(color=\"white\"),\n",
    "            ),\n",
    "            cells=dict(\n",
    "                values=[\n",
    "                    display_df[\"ticker\"], display_df[\"entry\"], display_df[\"exit\"],\n",
    "                    display_df[\"pnl\"].apply(lambda x: f\"${x:+,.0f}\"),\n",
    "                    display_df[\"pnl_pct\"].apply(lambda x: f\"{x:+.1f}%\"),\n",
    "                    display_df[\"exit_reason\"],\n",
    "                ],\n",
    "                fill_color=\"rgb(20,20,20)\", font=dict(color=\"white\"),\n",
    "            ),\n",
    "        ), row=2, col=2)\n",
    "\n",
    "    fig.update_layout(title=title, template=\"plotly_dark\",\n",
    "                      height=800, showlegend=False)\n",
    "    fig.show()\n",
    "    print(\"Interactive dashboard rendered.\")\n",
    "\n",
    "\n",
    "def _dashboard_matplotlib(engine, equity_df, trade_df, title):\n",
    "    \"\"\"Matplotlib fallback for the dashboard.\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "    if len(equity_df) > 0:\n",
    "        axes[0, 0].plot(equity_df[\"date\"], equity_df[\"equity\"], color=\"cyan\", linewidth=1.5)\n",
    "        axes[0, 0].axhline(y=engine.config.initial_capital, color=\"yellow\",\n",
    "                           linestyle=\"--\", alpha=0.3)\n",
    "    axes[0, 0].set_title(\"Equity Curve\")\n",
    "    axes[0, 0].set_ylabel(\"Equity ($)\")\n",
    "\n",
    "    by_ticker = trade_df.groupby(\"ticker\")[\"pnl\"].sum().sort_values()\n",
    "    colors = [\"lime\" if v > 0 else \"red\" for v in by_ticker.values]\n",
    "    axes[0, 1].barh(by_ticker.index, by_ticker.values, color=colors, alpha=0.8)\n",
    "    axes[0, 1].axvline(x=0, color=\"white\", alpha=0.3)\n",
    "    axes[0, 1].set_title(\"P&L by Ticker\")\n",
    "\n",
    "    axes[1, 0].hist([t.pnl for t in engine.trades], bins=25,\n",
    "                    color=\"cyan\", alpha=0.7, edgecolor=\"white\", linewidth=0.5)\n",
    "    axes[1, 0].axvline(x=0, color=\"yellow\", linestyle=\"--\", alpha=0.5)\n",
    "    axes[1, 0].set_title(\"Trade P&L Distribution\")\n",
    "    axes[1, 0].set_xlabel(\"P&L ($)\")\n",
    "\n",
    "    reasons = trade_df[\"exit_reason\"].value_counts()\n",
    "    axes[1, 1].pie(reasons.values, labels=reasons.index, autopct=\"%1.0f%%\",\n",
    "                   colors=sns.color_palette(\"bright\", len(reasons)))\n",
    "    axes[1, 1].set_title(\"Exit Reasons\")\n",
    "\n",
    "    plt.suptitle(title, fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\"Dashboard builder ready.\")\n",
    "print(f\"  Using: {'Plotly (interactive)' if HAS_PLOTLY else 'Matplotlib (static)'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s10-md",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Trade Persistence (SQLite)\n",
    "\n",
    "Store all trades, signals, and daily summaries in a SQLite database for\n",
    "post-session analysis. Uses **peewee** ORM if available, falls back to\n",
    "raw **sqlite3**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "s10-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database ready: paper_trades.db\n",
      "\n",
      "Existing sessions:\n",
      "     session_id  n_trades         first_trade          last_trade  total_pnl\n",
      "20260214_173351        25 2025-06-30 00:00:00 2026-02-13 00:00:00   -5871.22\n",
      "20260214_173109        25 2025-06-30 00:00:00 2026-02-13 00:00:00   -5871.22\n",
      "20260214_172417        25 2025-06-30 00:00:00 2026-02-13 00:00:00   -5871.22\n",
      "20260214_172159        25 2025-06-30 00:00:00 2026-02-13 00:00:00   -5871.22\n",
      "20260214_172002        25 2025-06-30 00:00:00 2026-02-13 00:00:00   -5871.22\n",
      "20260214_171854        25 2025-06-30 00:00:00 2026-02-13 00:00:00   -5871.22\n",
      "20260214_171725        25 2025-06-30 00:00:00 2026-02-13 00:00:00   -5871.22\n",
      "20260214_171508        25 2025-06-30 00:00:00 2026-02-13 00:00:00   -5871.22\n",
      "20260214_171307        25 2025-06-30 00:00:00 2026-02-13 00:00:00   -5871.22\n"
     ]
    }
   ],
   "source": [
    "class DBManager:\n",
    "    \"\"\"SQLite database manager for paper trade persistence.\"\"\"\n",
    "\n",
    "    def __init__(self, db_path=\"paper_trades.db\"):\n",
    "        self.db_path = db_path\n",
    "        self.conn = sqlite3.connect(db_path)\n",
    "        self._create_tables()\n",
    "        print(f\"Database ready: {db_path}\")\n",
    "\n",
    "    def _create_tables(self):\n",
    "        cursor = self.conn.cursor()\n",
    "        cursor.execute(\n",
    "            \"CREATE TABLE IF NOT EXISTS trades (\"\n",
    "            \"id INTEGER PRIMARY KEY AUTOINCREMENT, \"\n",
    "            \"ticker TEXT, direction TEXT, \"\n",
    "            \"entry_date TEXT, exit_date TEXT, \"\n",
    "            \"entry_price REAL, exit_price REAL, \"\n",
    "            \"shares INTEGER, pnl REAL, pnl_pct REAL, \"\n",
    "            \"exit_reason TEXT, entry_score REAL, exit_score REAL, \"\n",
    "            \"regime TEXT, bars_held INTEGER, \"\n",
    "            \"session_id TEXT, created_at TEXT DEFAULT CURRENT_TIMESTAMP)\"\n",
    "        )\n",
    "        cursor.execute(\n",
    "            \"CREATE TABLE IF NOT EXISTS signals (\"\n",
    "            \"id INTEGER PRIMARY KEY AUTOINCREMENT, \"\n",
    "            \"bar_index INTEGER, date TEXT, ticker TEXT, \"\n",
    "            \"composite_score REAL, regime TEXT, agreement REAL, \"\n",
    "            \"session_id TEXT)\"\n",
    "        )\n",
    "        cursor.execute(\n",
    "            \"CREATE TABLE IF NOT EXISTS daily_summary (\"\n",
    "            \"id INTEGER PRIMARY KEY AUTOINCREMENT, \"\n",
    "            \"date TEXT, equity REAL, cash REAL, \"\n",
    "            \"n_positions INTEGER, unrealized_pnl REAL, \"\n",
    "            \"session_id TEXT)\"\n",
    "        )\n",
    "        self.conn.commit()\n",
    "\n",
    "    def save_session(self, engine, session_id=None):\n",
    "        \"\"\"Save a complete trading session to the database.\"\"\"\n",
    "        if session_id is None:\n",
    "            session_id = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "        cursor = self.conn.cursor()\n",
    "\n",
    "        for t in engine.trades:\n",
    "            cursor.execute(\n",
    "                \"INSERT INTO trades (ticker, direction, entry_date, exit_date, \"\n",
    "                \"entry_price, exit_price, shares, pnl, pnl_pct, exit_reason, \"\n",
    "                \"entry_score, exit_score, regime, bars_held, session_id) \"\n",
    "                \"VALUES (?,?,?,?,?,?,?,?,?,?,?,?,?,?,?)\",\n",
    "                (t.ticker, t.direction, str(t.entry_date), str(t.exit_date),\n",
    "                 t.entry_price, t.exit_price, t.shares, t.pnl, t.pnl_pct,\n",
    "                 t.exit_reason, t.entry_score, t.exit_score, t.regime,\n",
    "                 t.bars_held, session_id))\n",
    "\n",
    "        for i, s in enumerate(engine.signal_log):\n",
    "            if i % 5 == 0:\n",
    "                cursor.execute(\n",
    "                    \"INSERT INTO signals (bar_index, date, ticker, composite_score, \"\n",
    "                    \"regime, agreement, session_id) VALUES (?,?,?,?,?,?,?)\",\n",
    "                    (s[\"bar_index\"], s[\"date\"], s[\"ticker\"],\n",
    "                     s[\"composite_score\"], s[\"regime\"], s[\"agreement\"], session_id))\n",
    "\n",
    "        for snap in engine.equity_snapshots:\n",
    "            cursor.execute(\n",
    "                \"INSERT INTO daily_summary (date, equity, cash, n_positions, \"\n",
    "                \"unrealized_pnl, session_id) VALUES (?,?,?,?,?,?)\",\n",
    "                (str(snap[\"date\"]), snap[\"equity\"], snap[\"cash\"],\n",
    "                 snap[\"n_positions\"], snap[\"unrealized_pnl\"], session_id))\n",
    "\n",
    "        self.conn.commit()\n",
    "        n_trades = len(engine.trades)\n",
    "        n_signals = len(engine.signal_log) // 5\n",
    "        n_snaps = len(engine.equity_snapshots)\n",
    "        print(f\"Session saved: {n_trades} trades, ~{n_signals} signals, {n_snaps} equity snapshots\")\n",
    "        return session_id\n",
    "\n",
    "    def load_trades(self, session_id=None):\n",
    "        \"\"\"Load trades from database as a DataFrame.\"\"\"\n",
    "        query = \"SELECT * FROM trades\"\n",
    "        if session_id:\n",
    "            query += f\" WHERE session_id = ?\"\n",
    "            return pd.read_sql(query, self.conn, params=[session_id])\n",
    "        return pd.read_sql(query, self.conn)\n",
    "\n",
    "    def load_equity(self, session_id=None):\n",
    "        \"\"\"Load equity curve from database.\"\"\"\n",
    "        query = \"SELECT * FROM daily_summary\"\n",
    "        if session_id:\n",
    "            query += \" WHERE session_id = ?\"\n",
    "            return pd.read_sql(query, self.conn, params=[session_id])\n",
    "        return pd.read_sql(query, self.conn)\n",
    "\n",
    "    def list_sessions(self):\n",
    "        \"\"\"List all saved sessions.\"\"\"\n",
    "        query = (\n",
    "            \"SELECT session_id, COUNT(*) as n_trades, \"\n",
    "            \"MIN(entry_date) as first_trade, MAX(exit_date) as last_trade, \"\n",
    "            \"ROUND(SUM(pnl), 2) as total_pnl \"\n",
    "            \"FROM trades GROUP BY session_id ORDER BY session_id DESC\"\n",
    "        )\n",
    "        return pd.read_sql(query, self.conn)\n",
    "\n",
    "    def close(self):\n",
    "        self.conn.close()\n",
    "\n",
    "\n",
    "db = DBManager(CONFIG.db_path)\n",
    "sessions = db.list_sessions()\n",
    "if len(sessions) > 0:\n",
    "    print(f\"\\nExisting sessions:\")\n",
    "    print(sessions.to_string(index=False))\n",
    "else:\n",
    "    print(\"No previous sessions found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s11-md",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. QuantStats Performance Analysis\n",
    "\n",
    "Generate a professional tearsheet comparing our paper trading performance\n",
    "against the SPY benchmark. QuantStats provides:\n",
    "- Sharpe, Sortino, Calmar ratios\n",
    "- Monthly returns heatmap\n",
    "- Drawdown analysis\n",
    "- Rolling statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "s11-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QuantStats analysis ready.\n",
      "  Using: quantstats\n"
     ]
    }
   ],
   "source": [
    "def generate_quantstats_report(engine, benchmark_ticker=\"SPY\", data_engine=None):\n",
    "    \"\"\"Generate QuantStats performance analysis.\n",
    "    Creates a tearsheet comparing strategy returns vs benchmark.\"\"\"\n",
    "    if not engine.equity_snapshots:\n",
    "        print(\"No equity data to analyze.\")\n",
    "        return None\n",
    "\n",
    "    equity_df = pd.DataFrame(engine.equity_snapshots).set_index(\"date\")\n",
    "    equity_df.index = pd.to_datetime(equity_df.index)\n",
    "    strategy_returns = equity_df[\"equity\"].pct_change().dropna()\n",
    "    strategy_returns.name = \"Strategy\"\n",
    "\n",
    "    benchmark_returns = None\n",
    "    if data_engine:\n",
    "        bench_data = data_engine.get_history(benchmark_ticker)\n",
    "        if bench_data is not None:\n",
    "            bench_returns = bench_data[\"Close\"].pct_change().dropna()\n",
    "            common_idx = strategy_returns.index.intersection(bench_returns.index)\n",
    "            if len(common_idx) > 10:\n",
    "                benchmark_returns = bench_returns.loc[common_idx]\n",
    "                benchmark_returns.name = benchmark_ticker\n",
    "                strategy_returns = strategy_returns.loc[common_idx]\n",
    "\n",
    "    if not HAS_QUANTSTATS:\n",
    "        print(\"QuantStats not available -- generating basic analysis.\\n\")\n",
    "        _basic_performance_report(strategy_returns, benchmark_returns)\n",
    "        return strategy_returns\n",
    "\n",
    "    print(\"Generating QuantStats analysis...\\n\")\n",
    "    qs.extend_pandas()\n",
    "\n",
    "    print(f\"{'='*55}\")\n",
    "    print(f\"  QUANTSTATS PERFORMANCE REPORT\")\n",
    "    print(f\"{'='*55}\\n\")\n",
    "\n",
    "    print(\"Key Metrics:\")\n",
    "    print(f\"  Sharpe Ratio:    {qs.stats.sharpe(strategy_returns):.2f}\")\n",
    "    print(f\"  Sortino Ratio:   {qs.stats.sortino(strategy_returns):.2f}\")\n",
    "    print(f\"  Max Drawdown:    {qs.stats.max_drawdown(strategy_returns)*100:.2f}%\")\n",
    "    print(f\"  Calmar Ratio:    {qs.stats.calmar(strategy_returns):.2f}\")\n",
    "    print(f\"  Win Rate:        {qs.stats.win_rate(strategy_returns)*100:.1f}%\")\n",
    "    print(f\"  Volatility:      {qs.stats.volatility(strategy_returns)*100:.2f}%\")\n",
    "\n",
    "    if benchmark_returns is not None:\n",
    "        print(f\"\\n  vs {benchmark_ticker}:\")\n",
    "        print(f\"  Benchmark Sharpe: {qs.stats.sharpe(benchmark_returns):.2f}\")\n",
    "        print(f\"  Information Ratio: {qs.stats.information_ratio(strategy_returns, benchmark_returns):.2f}\")\n",
    "\n",
    "    # Inline performance plots\n",
    "    try:\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "        cum_ret = (1 + strategy_returns).cumprod()\n",
    "        axes[0, 0].plot(cum_ret.index, cum_ret.values, color=\"cyan\", linewidth=1.5, label=\"Strategy\")\n",
    "        if benchmark_returns is not None:\n",
    "            bench_cum = (1 + benchmark_returns).cumprod()\n",
    "            axes[0, 0].plot(bench_cum.index, bench_cum.values, color=\"yellow\",\n",
    "                           linewidth=1, alpha=0.7, label=benchmark_ticker)\n",
    "        axes[0, 0].legend(fontsize=8)\n",
    "        axes[0, 0].set_title(\"Cumulative Returns\")\n",
    "        axes[0, 0].set_ylabel(\"Growth of $1\")\n",
    "\n",
    "        monthly = strategy_returns.resample(\"ME\").apply(lambda x: (1+x).prod()-1) * 100\n",
    "        colors = [\"lime\" if r > 0 else \"red\" for r in monthly.values]\n",
    "        axes[0, 1].bar(range(len(monthly)), monthly.values, color=colors, alpha=0.7)\n",
    "        axes[0, 1].axhline(y=0, color=\"white\", alpha=0.3)\n",
    "        axes[0, 1].set_title(\"Monthly Returns (%)\")\n",
    "\n",
    "        cum = (1 + strategy_returns).cumprod()\n",
    "        peak = cum.expanding().max()\n",
    "        dd = (cum - peak) / peak * 100\n",
    "        axes[1, 0].fill_between(dd.index, dd.values, 0, color=\"red\", alpha=0.4)\n",
    "        axes[1, 0].set_title(\"Drawdown (%)\")\n",
    "\n",
    "        rolling_sharpe = strategy_returns.rolling(30).apply(\n",
    "            lambda x: x.mean() / x.std() * np.sqrt(252) if x.std() > 0 else 0)\n",
    "        axes[1, 1].plot(rolling_sharpe.index, rolling_sharpe.values, color=\"orange\", linewidth=1)\n",
    "        axes[1, 1].axhline(y=0, color=\"white\", alpha=0.3)\n",
    "        axes[1, 1].axhline(y=1, color=\"lime\", linestyle=\"--\", alpha=0.3, label=\"Sharpe=1\")\n",
    "        axes[1, 1].set_title(\"Rolling 30-Day Sharpe\")\n",
    "        axes[1, 1].legend(fontsize=8)\n",
    "\n",
    "        plt.suptitle(\"QuantStats Performance Snapshot\", fontsize=14)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(f\"Plot generation error: {e}\")\n",
    "\n",
    "    return strategy_returns\n",
    "\n",
    "\n",
    "def _basic_performance_report(strategy_returns, benchmark_returns=None):\n",
    "    \"\"\"Fallback performance report without quantstats.\"\"\"\n",
    "    total_ret = (1 + strategy_returns).prod() - 1\n",
    "    sharpe = strategy_returns.mean() / strategy_returns.std() * np.sqrt(252) if strategy_returns.std() > 0 else 0\n",
    "    cum = (1 + strategy_returns).cumprod()\n",
    "    peak = cum.expanding().max()\n",
    "    max_dd = ((cum - peak) / peak).min()\n",
    "\n",
    "    print(f\"  Total Return:  {total_ret*100:+.2f}%\")\n",
    "    print(f\"  Sharpe Ratio:  {sharpe:.2f}\")\n",
    "    print(f\"  Max Drawdown:  {max_dd*100:.2f}%\")\n",
    "    print(f\"  Volatility:    {strategy_returns.std()*np.sqrt(252)*100:.2f}%\")\n",
    "\n",
    "    if benchmark_returns is not None:\n",
    "        bench_ret = (1 + benchmark_returns).prod() - 1\n",
    "        print(f\"  Benchmark Ret: {bench_ret*100:+.2f}%\")\n",
    "        print(f\"  Excess Return: {(total_ret - bench_ret)*100:+.2f}%\")\n",
    "\n",
    "\n",
    "print(\"QuantStats analysis ready.\")\n",
    "print(f\"  Using: {'quantstats' if HAS_QUANTSTATS else 'basic fallback'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s12-md",
   "metadata": {},
   "source": [
    "---\n",
    "## 11. Statistical Validation\n",
    "\n",
    "Rigorous statistical tests to determine if the strategy's performance\n",
    "is statistically significant or could be due to chance.\n",
    "\n",
    "| Test | Purpose |\n",
    "|------|---------|\n",
    "| **One-sample t-test** | Are mean returns significantly different from zero? |\n",
    "| **Bootstrap Sharpe CI** | Confidence interval for the Sharpe ratio |\n",
    "| **Mann-Whitney U** | Do returns differ between regimes? |\n",
    "| **QQ Plot** | Are returns normally distributed? |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "s12-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistical validation ready.\n"
     ]
    }
   ],
   "source": [
    "def statistical_validation(engine):\n",
    "    \"\"\"Run statistical validation tests on trading results.\"\"\"\n",
    "    if not engine.trades:\n",
    "        print(\"No trades to validate.\")\n",
    "        return\n",
    "\n",
    "    trade_returns = np.array([t.pnl_pct / 100 for t in engine.trades])\n",
    "    n = len(trade_returns)\n",
    "\n",
    "    print(f\"{'='*55}\")\n",
    "    print(f\"  STATISTICAL VALIDATION  ({n} trades)\")\n",
    "    print(f\"{'='*55}\\n\")\n",
    "\n",
    "    if not HAS_SCIPY:\n",
    "        print(\"scipy not available -- skipping statistical tests.\")\n",
    "        print(\"Install with: pip install scipy\")\n",
    "        return\n",
    "\n",
    "    # 1. One-sample t-test\n",
    "    t_stat, p_value = scipy_stats.ttest_1samp(trade_returns, 0)\n",
    "    sig = \"***\" if p_value < 0.01 else \"**\" if p_value < 0.05 else \"*\" if p_value < 0.10 else \"\"\n",
    "    print(f\"1. One-Sample t-test (H0: mean return = 0)\")\n",
    "    print(f\"   t-statistic: {t_stat:.3f}\")\n",
    "    print(f\"   p-value:     {p_value:.4f} {sig}\")\n",
    "    print(f\"   Mean return:  {np.mean(trade_returns)*100:+.3f}%\")\n",
    "    if p_value < 0.05:\n",
    "        print(f\"   -> Returns are statistically significant at 5% level.\")\n",
    "    else:\n",
    "        print(f\"   -> Cannot reject null hypothesis. Returns may be due to chance.\")\n",
    "\n",
    "    # 2. Bootstrap Sharpe CI\n",
    "    print(f\"\\n2. Bootstrap Sharpe Ratio (1000 resamples)\")\n",
    "    n_bootstrap = 1000\n",
    "    bootstrap_sharpes = []\n",
    "    for _ in range(n_bootstrap):\n",
    "        sample = np.random.choice(trade_returns, size=n, replace=True)\n",
    "        if sample.std() > 0:\n",
    "            sharpe = sample.mean() / sample.std() * np.sqrt(252)\n",
    "        else:\n",
    "            sharpe = 0\n",
    "        bootstrap_sharpes.append(sharpe)\n",
    "\n",
    "    ci_low = np.percentile(bootstrap_sharpes, 2.5)\n",
    "    ci_high = np.percentile(bootstrap_sharpes, 97.5)\n",
    "    median_sharpe = np.median(bootstrap_sharpes)\n",
    "    print(f\"   Median Sharpe: {median_sharpe:.2f}\")\n",
    "    print(f\"   95% CI:        [{ci_low:.2f}, {ci_high:.2f}]\")\n",
    "    if ci_low > 0:\n",
    "        print(f\"   -> Sharpe is significantly positive (CI excludes 0).\")\n",
    "    else:\n",
    "        print(f\"   -> Sharpe CI includes 0. Positive performance not guaranteed.\")\n",
    "\n",
    "    # 3. Mann-Whitney: regime comparison\n",
    "    print(f\"\\n3. Mann-Whitney U Test (Regime Comparison)\")\n",
    "    trending_returns = [t.pnl_pct / 100 for t in engine.trades\n",
    "                       if t.regime in (\"trend_up\", \"trend_down\")]\n",
    "    other_returns = [t.pnl_pct / 100 for t in engine.trades\n",
    "                    if t.regime not in (\"trend_up\", \"trend_down\")]\n",
    "\n",
    "    if len(trending_returns) >= 5 and len(other_returns) >= 5:\n",
    "        u_stat, p_mw = scipy_stats.mannwhitneyu(\n",
    "            trending_returns, other_returns, alternative=\"two-sided\")\n",
    "        print(f\"   Trending trades: {len(trending_returns)} (mean: {np.mean(trending_returns)*100:+.2f}%)\")\n",
    "        print(f\"   Other trades:    {len(other_returns)} (mean: {np.mean(other_returns)*100:+.2f}%)\")\n",
    "        print(f\"   U-statistic: {u_stat:.1f}, p-value: {p_mw:.4f}\")\n",
    "        if p_mw < 0.05:\n",
    "            print(f\"   -> Significant difference between regime performance.\")\n",
    "        else:\n",
    "            print(f\"   -> No significant difference between regimes.\")\n",
    "    else:\n",
    "        print(f\"   Insufficient trades per regime for comparison.\")\n",
    "\n",
    "    # 4. Normality test\n",
    "    print(f\"\\n4. Shapiro-Wilk Normality Test\")\n",
    "    test_sample = trade_returns[:min(n, 500)]\n",
    "    w_stat, p_norm = scipy_stats.shapiro(test_sample)\n",
    "    print(f\"   W-statistic: {w_stat:.4f}, p-value: {p_norm:.4f}\")\n",
    "    if p_norm < 0.05:\n",
    "        print(f\"   -> Returns are NOT normally distributed (common for trading).\")\n",
    "    else:\n",
    "        print(f\"   -> Returns appear normally distributed.\")\n",
    "\n",
    "    # Visualizations\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "    scipy_stats.probplot(trade_returns, dist=\"norm\", plot=axes[0, 0])\n",
    "    axes[0, 0].set_title(\"QQ Plot (Returns vs Normal)\")\n",
    "    axes[0, 0].get_lines()[0].set_color(\"cyan\")\n",
    "    axes[0, 0].get_lines()[1].set_color(\"yellow\")\n",
    "\n",
    "    axes[0, 1].hist(trade_returns * 100, bins=30, density=True,\n",
    "                    color=\"cyan\", alpha=0.7, edgecolor=\"white\", linewidth=0.5)\n",
    "    x = np.linspace(trade_returns.min() * 100, trade_returns.max() * 100, 100)\n",
    "    axes[0, 1].plot(x, scipy_stats.norm.pdf(x, np.mean(trade_returns)*100,\n",
    "                    np.std(trade_returns)*100),\n",
    "                    color=\"yellow\", linewidth=2, label=\"Normal fit\")\n",
    "    axes[0, 1].set_title(\"Return Distribution vs Normal\")\n",
    "    axes[0, 1].set_xlabel(\"Return (%)\")\n",
    "    axes[0, 1].legend(fontsize=8)\n",
    "\n",
    "    axes[1, 0].hist(bootstrap_sharpes, bins=40, color=\"orange\", alpha=0.7,\n",
    "                    edgecolor=\"white\", linewidth=0.5)\n",
    "    axes[1, 0].axvline(x=ci_low, color=\"red\", linestyle=\"--\", label=f\"95% CI: [{ci_low:.2f}, {ci_high:.2f}]\")\n",
    "    axes[1, 0].axvline(x=ci_high, color=\"red\", linestyle=\"--\")\n",
    "    axes[1, 0].axvline(x=0, color=\"yellow\", linestyle=\"--\", alpha=0.5, label=\"Zero\")\n",
    "    axes[1, 0].set_title(\"Bootstrap Sharpe Distribution\")\n",
    "    axes[1, 0].set_xlabel(\"Sharpe Ratio\")\n",
    "    axes[1, 0].legend(fontsize=8)\n",
    "\n",
    "    regime_groups = defaultdict(list)\n",
    "    for t in engine.trades:\n",
    "        regime_groups[t.regime].append(t.pnl_pct)\n",
    "    if regime_groups:\n",
    "        labels = list(regime_groups.keys())\n",
    "        data = [regime_groups[k] for k in labels]\n",
    "        bp = axes[1, 1].boxplot(data, labels=labels, patch_artist=True)\n",
    "        colors_map = {\"trend_up\": \"lime\", \"trend_down\": \"red\",\n",
    "                     \"ranging\": \"yellow\", \"volatile\": \"gray\"}\n",
    "        for patch, label in zip(bp[\"boxes\"], labels):\n",
    "            patch.set_facecolor(colors_map.get(label, \"cyan\"))\n",
    "            patch.set_alpha(0.6)\n",
    "        axes[1, 1].axhline(y=0, color=\"white\", alpha=0.3)\n",
    "        axes[1, 1].set_title(\"Returns by Regime\")\n",
    "        axes[1, 1].set_ylabel(\"Return (%)\")\n",
    "\n",
    "    plt.suptitle(\"Statistical Validation\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return {\"t_test_p\": p_value, \"sharpe_ci\": (ci_low, ci_high), \"normality_p\": p_norm}\n",
    "\n",
    "\n",
    "print(\"Statistical validation ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s13-md",
   "metadata": {},
   "source": [
    "---\n",
    "## 12. Risk Management Dashboard\n",
    "\n",
    "Comprehensive risk analysis with:\n",
    "- Drawdown with alert zones (yellow >5%, red >10%)\n",
    "- P&L concentration by ticker\n",
    "- Exit reason breakdown\n",
    "- Rolling 30-bar Sharpe ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "s13-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Risk dashboard ready.\n"
     ]
    }
   ],
   "source": [
    "def risk_dashboard(engine):\n",
    "    \"\"\"Generate a risk management dashboard from trading results.\"\"\"\n",
    "    if not engine.trades or not engine.equity_snapshots:\n",
    "        print(\"No data for risk dashboard.\")\n",
    "        return\n",
    "\n",
    "    equity_df = pd.DataFrame(engine.equity_snapshots).set_index(\"date\")\n",
    "    equity_df.index = pd.to_datetime(equity_df.index)\n",
    "\n",
    "    fig = plt.figure(figsize=(16, 14))\n",
    "    gs = gridspec.GridSpec(3, 2, hspace=0.35, wspace=0.3)\n",
    "\n",
    "    # 1. Drawdown with alert zones\n",
    "    ax1 = fig.add_subplot(gs[0, :])\n",
    "    equity = equity_df[\"equity\"]\n",
    "    peak = equity.expanding().max()\n",
    "    dd = (equity - peak) / peak * 100\n",
    "    ax1.fill_between(dd.index, dd.values, 0, color=\"red\", alpha=0.3)\n",
    "    ax1.axhline(y=-5, color=\"yellow\", linestyle=\"--\", alpha=0.7, label=\"Warning (-5%)\")\n",
    "    ax1.axhline(y=-10, color=\"red\", linestyle=\"--\", alpha=0.7, label=\"Danger (-10%)\")\n",
    "    ax1.axhline(y=-15, color=\"magenta\", linestyle=\"--\", alpha=0.7, label=\"Critical (-15%)\")\n",
    "    ax1.set_ylabel(\"Drawdown (%)\")\n",
    "    ax1.set_title(\"Drawdown with Alert Zones\")\n",
    "    ax1.legend(fontsize=8)\n",
    "    ax1.fill_between(dd.index, -5, 0, alpha=0.05, color=\"green\")\n",
    "    ax1.fill_between(dd.index, -10, -5, alpha=0.05, color=\"yellow\")\n",
    "    ax1.fill_between(dd.index, dd.values.min() - 2, -10, alpha=0.05, color=\"red\")\n",
    "\n",
    "    # 2. P&L concentration\n",
    "    ax2 = fig.add_subplot(gs[1, 0])\n",
    "    trade_pnls = pd.DataFrame([{\"ticker\": t.ticker, \"pnl\": abs(t.pnl)} for t in engine.trades])\n",
    "    if len(trade_pnls) > 0:\n",
    "        concentration = trade_pnls.groupby(\"ticker\")[\"pnl\"].sum().sort_values(ascending=False)\n",
    "        cum_pct = concentration.cumsum() / concentration.sum() * 100\n",
    "        ax2.bar(range(len(concentration)), concentration.values, color=\"cyan\", alpha=0.8)\n",
    "        ax2_twin = ax2.twinx()\n",
    "        ax2_twin.plot(range(len(cum_pct)), cum_pct.values, color=\"yellow\",\n",
    "                     marker=\"o\", linewidth=2)\n",
    "        ax2_twin.axhline(y=80, color=\"red\", linestyle=\"--\", alpha=0.5)\n",
    "        ax2_twin.set_ylabel(\"Cumulative %\", color=\"yellow\")\n",
    "        ax2.set_xticks(range(len(concentration)))\n",
    "        ax2.set_xticklabels(concentration.index, rotation=45, ha=\"right\", fontsize=8)\n",
    "    ax2.set_title(\"P&L Concentration (Absolute)\")\n",
    "    ax2.set_ylabel(\"Absolute P&L ($)\")\n",
    "\n",
    "    # 3. Exit reason pie\n",
    "    ax3 = fig.add_subplot(gs[1, 1])\n",
    "    reasons = pd.Series([t.exit_reason for t in engine.trades]).value_counts()\n",
    "    colors_list = [\"red\", \"lime\", \"cyan\", \"yellow\", \"magenta\", \"orange\"]\n",
    "    ax3.pie(reasons.values, labels=reasons.index, autopct=\"%1.0f%%\",\n",
    "            colors=colors_list[:len(reasons)], textprops={\"fontsize\": 9})\n",
    "    ax3.set_title(\"Exit Reasons\")\n",
    "\n",
    "    # 4. Rolling 30-bar Sharpe\n",
    "    ax4 = fig.add_subplot(gs[2, 0])\n",
    "    returns = equity.pct_change().dropna()\n",
    "    if len(returns) > 30:\n",
    "        rolling_sharpe = returns.rolling(30).apply(\n",
    "            lambda x: x.mean() / x.std() * np.sqrt(252) if x.std() > 0 else 0)\n",
    "        ax4.plot(rolling_sharpe.index, rolling_sharpe.values, color=\"orange\", linewidth=1.5)\n",
    "        ax4.axhline(y=0, color=\"white\", alpha=0.3)\n",
    "        ax4.axhline(y=1, color=\"lime\", linestyle=\"--\", alpha=0.3, label=\"Sharpe=1\")\n",
    "        ax4.axhline(y=-1, color=\"red\", linestyle=\"--\", alpha=0.3, label=\"Sharpe=-1\")\n",
    "        ax4.fill_between(rolling_sharpe.index, rolling_sharpe.values, 0,\n",
    "                        where=rolling_sharpe.values > 0, alpha=0.1, color=\"lime\")\n",
    "        ax4.fill_between(rolling_sharpe.index, rolling_sharpe.values, 0,\n",
    "                        where=rolling_sharpe.values < 0, alpha=0.1, color=\"red\")\n",
    "    ax4.set_title(\"Rolling 30-Day Sharpe Ratio\")\n",
    "    ax4.set_ylabel(\"Sharpe\")\n",
    "    ax4.legend(fontsize=8)\n",
    "\n",
    "    # 5. Win rate by holding period\n",
    "    ax5 = fig.add_subplot(gs[2, 1])\n",
    "    hold_groups = defaultdict(list)\n",
    "    for t in engine.trades:\n",
    "        if t.bars_held <= 3:\n",
    "            bucket = \"1-3 bars\"\n",
    "        elif t.bars_held <= 7:\n",
    "            bucket = \"4-7 bars\"\n",
    "        elif t.bars_held <= 14:\n",
    "            bucket = \"8-14 bars\"\n",
    "        else:\n",
    "            bucket = \"15+ bars\"\n",
    "        hold_groups[bucket].append(1 if t.pnl > 0 else 0)\n",
    "\n",
    "    if hold_groups:\n",
    "        buckets = [\"1-3 bars\", \"4-7 bars\", \"8-14 bars\", \"15+ bars\"]\n",
    "        existing_buckets = [b for b in buckets if b in hold_groups]\n",
    "        win_rates = [np.mean(hold_groups[b]) * 100 for b in existing_buckets]\n",
    "        counts = [len(hold_groups[b]) for b in existing_buckets]\n",
    "        bars_plot = ax5.bar(range(len(existing_buckets)), win_rates,\n",
    "                          color=\"cyan\", alpha=0.8)\n",
    "        ax5.set_xticks(range(len(existing_buckets)))\n",
    "        ax5.set_xticklabels(existing_buckets, fontsize=9)\n",
    "        ax5.axhline(y=50, color=\"yellow\", linestyle=\"--\", alpha=0.5)\n",
    "        ax5.set_ylabel(\"Win Rate (%)\")\n",
    "        ax5.set_title(\"Win Rate by Holding Period\")\n",
    "        for bar, count in zip(bars_plot, counts):\n",
    "            ax5.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
    "                    f\"n={count}\", ha=\"center\", fontsize=8, color=\"white\")\n",
    "\n",
    "    plt.suptitle(\"Risk Management Dashboard\", fontsize=14, y=1.0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "print(\"Risk dashboard ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s14-md",
   "metadata": {},
   "source": [
    "---\n",
    "## 13. Full System Demo\n",
    "\n",
    "End-to-end execution: data load -> pre-market scan -> trading session ->\n",
    "database persistence -> QuantStats analysis -> statistical validation ->\n",
    "risk dashboard -> interactive dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "s14-code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1: Pre-Market Scan\n",
      "\n",
      "\n",
      "===========================================================================\n",
      "  PRE-MARKET SCANNER  |  8 stocks scanned\n",
      "===========================================================================\n",
      "\n",
      "  Ticker      Price   Score   Agree Regime       Action    \n",
      "  --------------------------------------------------------------\n",
      "      NVDA  $ 182.81 +0.153   0.20 ranging      --        \n",
      "      META  $ 639.77 +0.111   0.30 ranging      --        \n",
      "      AAPL  $ 255.78 +0.059   0.00 volatile     --        \n",
      "      TSLA  $ 417.44 -0.091   0.00 volatile     --        \n",
      "      AMD   $ 207.32 -0.210   0.60 volatile     --        \n",
      "      GOOGL $ 305.72 -0.288   0.10 trend_down   --        \n",
      "      MSFT  $ 401.32 -0.342   0.20 trend_down   --        \n",
      "      AMZN  $ 198.79 -0.557   0.40 trend_down   --        \n",
      "\n",
      "  Actionable: 0 stocks meet entry criteria\n",
      "\n",
      "STEP 2: Trading Session\n",
      "\n",
      "============================================================\n",
      "  TRADING SESSION (LIVE)\n",
      "============================================================\n",
      "  Capital: $100,000 | Max positions: 5\n",
      "  Universe: ['NVDA', 'AAPL', 'TSLA', 'AMD', 'MSFT', 'META', 'AMZN', 'GOOGL']\n",
      "\n",
      "\n",
      "============================================================\n",
      "  SESSION COMPLETE (0.0s, 0 bars)\n",
      "============================================================\n",
      "  No trades executed.\n",
      "\n",
      "STEP 3: Persist to Database\n",
      "\n",
      "Session saved: 0 trades, ~0 signals, 0 equity snapshots\n",
      "\n",
      "All sessions:\n",
      "     session_id  n_trades         first_trade          last_trade  total_pnl\n",
      "20260214_173351        25 2025-06-30 00:00:00 2026-02-13 00:00:00   -5871.22\n",
      "20260214_173109        25 2025-06-30 00:00:00 2026-02-13 00:00:00   -5871.22\n",
      "20260214_172417        25 2025-06-30 00:00:00 2026-02-13 00:00:00   -5871.22\n",
      "20260214_172159        25 2025-06-30 00:00:00 2026-02-13 00:00:00   -5871.22\n",
      "20260214_172002        25 2025-06-30 00:00:00 2026-02-13 00:00:00   -5871.22\n",
      "20260214_171854        25 2025-06-30 00:00:00 2026-02-13 00:00:00   -5871.22\n",
      "20260214_171725        25 2025-06-30 00:00:00 2026-02-13 00:00:00   -5871.22\n",
      "20260214_171508        25 2025-06-30 00:00:00 2026-02-13 00:00:00   -5871.22\n",
      "20260214_171307        25 2025-06-30 00:00:00 2026-02-13 00:00:00   -5871.22\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "#  FULL SYSTEM DEMO\n",
    "# ===================================================================\n",
    "\n",
    "# 1. Pre-market scan\n",
    "print(\"STEP 1: Pre-Market Scan\\n\")\n",
    "scan_results = scanner.scan(bar_index=CONFIG.warmup_bars)\n",
    "scanner.print_brief(scan_results)\n",
    "\n",
    "# 2. Run trading session\n",
    "print(\"\\nSTEP 2: Trading Session\\n\")\n",
    "engine = run_trading_session(\n",
    "    CONFIG, data_engine, signal_hub,\n",
    "    alpaca_client=alpaca_client,\n",
    "    verbose=True, progress_every=30,\n",
    ")\n",
    "\n",
    "# 3. Save to database\n",
    "print(\"\\nSTEP 3: Persist to Database\\n\")\n",
    "session_id = db.save_session(engine)\n",
    "\n",
    "print(\"\\nAll sessions:\")\n",
    "print(db.list_sessions().to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "s14-analysis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 4: QuantStats Performance Analysis\n",
      "\n",
      "No equity data to analyze.\n",
      "\n",
      "STEP 5: Statistical Validation\n",
      "\n",
      "No trades to validate.\n",
      "\n",
      "STEP 6: Risk Management Dashboard\n",
      "\n",
      "No data for risk dashboard.\n",
      "\n",
      "STEP 7: Interactive Dashboard\n",
      "\n",
      "No trades to display.\n",
      "\n",
      "============================================================\n",
      "  DEMO COMPLETE\n",
      "============================================================\n",
      "  Session: 20260214_174011\n",
      "  Trades:  0\n",
      "  Return:  +0.00%\n",
      "  Sharpe:  0.00\n",
      "  Database: paper_trades.db\n",
      "\n",
      "  All results persisted. Reload with:\n",
      "    db = DBManager('paper_trades.db')\n",
      "    trades = db.load_trades('20260214_174011')\n"
     ]
    }
   ],
   "source": [
    "# 4. QuantStats analysis\n",
    "print(\"STEP 4: QuantStats Performance Analysis\\n\")\n",
    "strategy_returns = generate_quantstats_report(engine, \"SPY\", data_engine)\n",
    "\n",
    "# 5. Statistical validation\n",
    "print(\"\\nSTEP 5: Statistical Validation\\n\")\n",
    "stats_results = statistical_validation(engine)\n",
    "\n",
    "# 6. Risk management dashboard\n",
    "print(\"\\nSTEP 6: Risk Management Dashboard\\n\")\n",
    "risk_dashboard(engine)\n",
    "\n",
    "# 7. Interactive dashboard\n",
    "print(\"\\nSTEP 7: Interactive Dashboard\\n\")\n",
    "build_dashboard(engine, title=f\"Paper Trading Session: {session_id}\")\n",
    "\n",
    "# Final summary\n",
    "m = engine.get_metrics()\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"  DEMO COMPLETE\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"  Session: {session_id}\")\n",
    "print(f\"  Trades:  {m.get('total_trades', 0)}\")\n",
    "print(f\"  Return:  {m.get('total_return_pct', 0):+.2f}%\")\n",
    "print(f\"  Sharpe:  {m.get('sharpe_ratio', 0):.2f}\")\n",
    "if stats_results:\n",
    "    ci = stats_results.get(\"sharpe_ci\", (0, 0))\n",
    "    print(f\"  Sharpe 95% CI: [{ci[0]:.2f}, {ci[1]:.2f}]\")\n",
    "print(f\"  Database: {CONFIG.db_path}\")\n",
    "print(f\"\\n  All results persisted. Reload with:\")\n",
    "print(f\"    db = DBManager('{CONFIG.db_path}')\")\n",
    "print(f\"    trades = db.load_trades('{session_id}')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s15-md",
   "metadata": {},
   "source": [
    "---\n",
    "## 14. Next Steps: Going Live\n",
    "\n",
    "### From Paper to Real Money\n",
    "\n",
    "This notebook gives you a **complete paper trading system**. Before going live,\n",
    "work through this checklist carefully.\n",
    "\n",
    "---\n",
    "\n",
    "### Pre-Live Checklist\n",
    "\n",
    "| Category | Item | Notes |\n",
    "|----------|------|-------|\n",
    "| **Psychology** | Paper trade for 30+ days | Track emotions, not just P&L |\n",
    "| **Psychology** | Define max daily loss | Stop trading after hitting limit |\n",
    "| **Psychology** | Accept that losses are normal | Even 50% win rate can be profitable |\n",
    "| **Slippage** | Test with higher slippage (0.1-0.2%) | Real fills are worse than backtests |\n",
    "| **PDT Rule** | Maintain $25K+ account | Pattern Day Trader rule applies to <$25K accounts |\n",
    "| **Capital** | Never risk more than you can afford to lose | This is research, not financial advice |\n",
    "| **Infrastructure** | Reliable internet + power backup | Missed exit signals can be costly |\n",
    "| **Data Quality** | Verify data source reliability | Bad data = bad signals |\n",
    "| **Taxes** | Understand wash sale rules | Short-term gains are taxed as income |\n",
    "| **Taxes** | Track cost basis carefully | Your broker should handle this |\n",
    "\n",
    "---\n",
    "\n",
    "### Alpaca Go-Live Steps\n",
    "\n",
    "```python\n",
    "# 1. Create Alpaca account at https://alpaca.markets\n",
    "# 2. Get API keys from the dashboard\n",
    "# 3. Set environment variables:\n",
    "#    export ALPACA_KEY=\"your-key\"\n",
    "#    export ALPACA_SECRET=\"your-secret\"\n",
    "\n",
    "# 4. Switch to live paper trading:\n",
    "CONFIG.simulation_mode = False\n",
    "\n",
    "# 5. Run the trading session:\n",
    "engine = run_trading_session(CONFIG, data_engine, signal_hub)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Enhancement Ideas\n",
    "\n",
    "| Enhancement | Difficulty | Impact |\n",
    "|-------------|-----------|--------|\n",
    "| Real-time sentiment from news APIs | Medium | High |\n",
    "| Live Chronos forecasts (not proxy) | Low | Medium |\n",
    "| Intraday (5-min) bar support | High | High |\n",
    "| Multi-timeframe confirmation | Medium | Medium |\n",
    "| Sector rotation overlay | Medium | Medium |\n",
    "| Options integration | High | High |\n",
    "| Telegram/Discord alerts | Low | Medium |\n",
    "| Web dashboard (Dash/Streamlit) | Medium | High |\n",
    "\n",
    "---\n",
    "\n",
    "### Series Complete!\n",
    "\n",
    "You have built a comprehensive day trading research environment:\n",
    "\n",
    "| Notebook | What You Built |\n",
    "|----------|---------------|\n",
    "| **01** | Market data, candlesticks, indicators, LSTM intro |\n",
    "| **02** | Multi-model NLP sentiment pipeline |\n",
    "| **03** | Custom backtesting engine with 5 strategies |\n",
    "| **04** | Chronos zero-shot time series forecasting |\n",
    "| **05** | Local LLM financial analysis (Phi-3, Mistral) |\n",
    "| **06** | Multi-signal composite scoring, regime detection, Monte Carlo |\n",
    "| **07** | Paper trading system tying it all together |\n",
    "\n",
    "**Remember**: This is an educational research project. Past performance in\n",
    "backtesting does not guarantee future results. Always practice responsible\n",
    "risk management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "s15-cleanup",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory freed.\n",
      "\n",
      "Notebook 07 complete. Your paper trading system is ready.\n",
      "Run the full demo cell above to execute a complete session.\n",
      "\n",
      "To go live with Alpaca paper trading:\n",
      "  1. pip install alpaca-py\n",
      "  2. export ALPACA_KEY='...' ALPACA_SECRET='...'\n",
      "  3. Set CONFIG.simulation_mode = False\n",
      "  4. Re-run the trading session cell\n"
     ]
    }
   ],
   "source": [
    "# Clean up\n",
    "db.close()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"GPU memory freed.\")\n",
    "\n",
    "print(\"\\nNotebook 07 complete. Your paper trading system is ready.\")\n",
    "print(\"Run the full demo cell above to execute a complete session.\")\n",
    "print(\"\\nTo go live with Alpaca paper trading:\")\n",
    "print(\"  1. pip install alpaca-py\")\n",
    "print(\"  2. export ALPACA_KEY='...' ALPACA_SECRET='...'\")\n",
    "print(\"  3. Set CONFIG.simulation_mode = False\")\n",
    "print(\"  4. Re-run the trading session cell\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75c2a81d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Feb 14 17:40:11 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 580.126.09             Driver Version: 580.126.09     CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4090        Off |   00000000:04:00.0 Off |                  Off |\n",
      "|  0%   33C    P8              7W /  450W |      20MiB /  24564MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 2070 ...    Off |   00000000:2B:00.0  On |                  N/A |\n",
      "| 24%   31C    P8             11W /  215W |     444MiB /   8192MiB |     35%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            2700      G   /usr/bin/gnome-shell                      6MiB |\n",
      "|    1   N/A  N/A            2700      G   /usr/bin/gnome-shell                    270MiB |\n",
      "|    1   N/A  N/A            5154      G   ...rack-uuid=3190708988185955192        101MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
